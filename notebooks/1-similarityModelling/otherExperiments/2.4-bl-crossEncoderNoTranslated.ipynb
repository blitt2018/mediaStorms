{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News Article Similarity Modelling\n",
    "- Cross encoding \n",
    "- Translated data \n",
    "- Using Title "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch \n",
    "import random\n",
    "from torch import nn\n",
    "from transformers import RobertaTokenizer, PreTrainedTokenizer, DistilBertTokenizer, DistilBertModel, RobertaModel\n",
    "from sentence_transformers import SentenceTransformer, SentencesDataset, InputExample, losses\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from transformers.optimization import get_linear_schedule_with_warmup\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.nn import CosineEmbeddingLoss\n",
    "import transformers\n",
    "import pickle \n",
    "import time\n",
    "#Build up to SBERT model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE_NUM = 4\n",
    "BATCH_SIZE = 5\n",
    "EPOCHS = 3\n",
    "SEED = 85\n",
    "FOLDS = 5\n",
    "RDROP_WEIGHT = .1\n",
    "FORWARD_WEIGHT = (1 - RDROP_WEIGHT) / 2\n",
    "\n",
    "device = torch.device(\"cuda:\" + str(DEVICE_NUM) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "RESULTS_PATH = \"/home/blitt/projects/localNews/models/sentEmbeddings/3.0-crossModelAblation/noTranslated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set seeds \n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"/shared/3/projects/benlitterer/localNews/NetworkMVP/translatedCleaned.tsv\", sep=\"\\t\")\n",
    "df = pd.read_csv(\"/home/blitt/projects/localNews/data/processed/translated_200_56.tsv\", sep=\"\\t\")\n",
    "\n",
    "#put ground truth values into a list \n",
    "df[\"ground_truth\"] = df['Overall']\n",
    "\n",
    "#get only the columns we need \n",
    "#for when using merged text\n",
    "leanDf = df[[\"ground_truth\",  'text1Merged', 'text2Merged', 'url1_lang', 'url2_lang']].dropna()\n",
    "\n",
    "#rescale data from (0, 4): (0, 1)\n",
    "leanDf[\"ground_truth\"] = 1 - ((leanDf[\"ground_truth\"] - 1) / 3)\n",
    "\n",
    "#reset index so it is contiguous set of numbers \n",
    "leanDf = leanDf.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JUST FOR THIS ABLATION \n",
    "leanDf = leanDf[(leanDf[\"url1_lang\"] == \"en\") & (leanDf[\"url2_lang\"] == \"en\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(token_embeddings, attention_mask):\n",
    "     #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module): \n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()\n",
    "        self.model = RobertaModel.from_pretrained('roberta-base')\n",
    "        self.l1 = nn.Linear(768, 256).to(device)\n",
    "        self.l2 = nn.Linear(256, 1)\n",
    "        self.GELU = nn.GELU()\n",
    "        self.loss_func = torch.nn.MSELoss(reduction=\"mean\")\n",
    "        \n",
    "    def mean_pooling(self, token_embeddings, attention_mask): \n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask): \n",
    "        \n",
    "        #encode sentence and get mean pooled sentence representation \n",
    "        encoding1 = self.model(input_ids, attention_mask=attention_mask)[0]  #all token embeddings\n",
    "        meanPooled1 = self.mean_pooling(encoding1, attention_mask)\n",
    "       \n",
    "        pred1 = self.l2(self.GELU(self.l1(meanPooled1)))\n",
    "        \n",
    "        encoding2 = self.model(input_ids, attention_mask=attention_mask)[0]  #all token embeddings\n",
    "        meanPooled2 = self.mean_pooling(encoding2, attention_mask)\n",
    "        \n",
    "        pred2 = self.l2(self.GELU(self.l1(meanPooled2)))\n",
    "        \n",
    "        \n",
    "        return [pred1, pred2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, validLoader, loss_func): \n",
    "    model.eval()\n",
    "    lossList = []\n",
    "    predList = []\n",
    "    GT = []\n",
    "\n",
    "    i = True \n",
    "    for batch in validLoader: \n",
    "\n",
    "        # prepare batches and more all to the active device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        label = batch['ground_truth'].to(device).unsqueeze(1)\n",
    "\n",
    "        #send batch info through model \n",
    "        pred1, pred2 = model(input_ids, attention_mask)\n",
    "        #pred1, pred2 = pred1.unsqueeze(0), pred2.unsqueeze(0)\n",
    "        \n",
    "        #get loss relating to label prediction \n",
    "        loss1 = loss_func(label, pred1) * FORWARD_WEIGHT \n",
    "        loss2 = loss_func(label, pred2) * FORWARD_WEIGHT\n",
    "        loss_r = loss_func(pred1, pred2) * RDROP_WEIGHT\n",
    "        loss = (loss1 + loss2 + loss_r)\n",
    "        \n",
    "        #get output metrics \n",
    "        lossList.append(loss1.detach().cpu().item())\n",
    "        predList.append(float(pred1.detach().cpu()))\n",
    "        GT.append(float(label.detach().cpu()))\n",
    "        \n",
    "        del loss1\n",
    "        del loss2\n",
    "        del loss_r\n",
    "        del loss\n",
    "        del pred1\n",
    "        del pred2\n",
    "        del label \n",
    "    #print(vGT)\n",
    "    return [lossList, predList, GT]\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up relevant variables \n",
    "def train(trainDataset, validDataset): \n",
    "    torch.cuda.empty_cache()\n",
    "    #get loaders \n",
    "    trainLoader = torch.utils.data.DataLoader(\n",
    "        trainDataset, batch_size=BATCH_SIZE, shuffle=True\n",
    "    )\n",
    "    validLoader = torch.utils.data.DataLoader(\n",
    "        validDataset, batch_size=1, shuffle=True\n",
    "    )\n",
    "    \n",
    "    trainLen = len(trainDataset)\n",
    "\n",
    "    #load the model \n",
    "    model = Model().to(device)\n",
    "\n",
    "    #TODO: double check on if reduction=\"mean\" is the right move here...\n",
    "    #could cosine similarity also work..? I think that is between the two predicted vectors though.. \n",
    "    loss_func = torch.nn.MSELoss(reduction=\"mean\")\n",
    "\n",
    "    # we would initialize everything first\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "\n",
    "    #set up scheduler\n",
    "    # and setup a warmup for the first ~10% steps\n",
    "    total_steps = int((trainLen*EPOCHS) / BATCH_SIZE)\n",
    "    warmup_steps = int(0.1 * total_steps)\n",
    "    scheduler = get_linear_schedule_with_warmup(optim, num_warmup_steps=warmup_steps, num_training_steps=total_steps - warmup_steps)\n",
    "    \n",
    "    \n",
    "    #now run training loop \n",
    "    lossList = []\n",
    "    validMetrics = []\n",
    "    subLossList = []\n",
    "    # increase from 1 epoch if need be \n",
    "    for epoch in range(EPOCHS):\n",
    "        torch.cuda.empty_cache()\n",
    "        model.train()  # make sure model is in training mode\n",
    "\n",
    "        # initialize the dataloader loop with tqdm (tqdm == progress bar)\n",
    "        loop = tqdm(trainLoader, leave=True)\n",
    "\n",
    "        validMetrics.append(validation(model, validLoader, loss_func))\n",
    "        model.train()\n",
    "\n",
    "        for i, batch in enumerate(loop): \n",
    "            # zero all gradients on each new step\n",
    "            optim.zero_grad()\n",
    "\n",
    "            # prepare batches and more all to the active device\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            label = batch['ground_truth'].to(device).unsqueeze(1)\n",
    "\n",
    "            #send batch info through model \n",
    "            pred1, pred2 = model(input_ids, attention_mask)\n",
    "            #pred1, pred2 = pred1.unsqueeze(0), pred2.unsqueeze(0)\n",
    "            \n",
    "            print(label.size())\n",
    "            print(pred1.size())\n",
    "            print(pred2.size())\n",
    "            #get loss for label prediction, rdrop \n",
    "            loss1 = loss_func(label, pred1) * FORWARD_WEIGHT \n",
    "            loss2 = loss_func(label, pred2) * FORWARD_WEIGHT\n",
    "            loss_r = loss_func(pred1, pred2) * RDROP_WEIGHT\n",
    "            loss = (loss1 + loss2 + loss_r)\n",
    "\n",
    "            # using loss, calculate gradients and then optimize\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            #get mean loss over last 20 batches \n",
    "            if i % 20 == 0: \n",
    "                lossList.append(np.mean(subLossList))\n",
    "                subLossList = []\n",
    "                pass\n",
    "\n",
    "            subLossList.append(float(loss.detach().item()))\n",
    "            \n",
    "\n",
    "            # update learning rate scheduler\n",
    "            scheduler.step()\n",
    "\n",
    "            # update the TDQM progress bar\n",
    "            loop.set_description(f'Epoch {epoch}')\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "            del loss1\n",
    "            del loss2\n",
    "            del loss_r\n",
    "            del loss\n",
    "        print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
    "        print(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "        print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))\n",
    "\n",
    "    validMetrics.append(validation(model, validLoader, loss_func))\n",
    "    return validMetrics \n",
    "    del model\n",
    "    del trainLoader\n",
    "    del validLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=FOLDS, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total df len: 4806\n",
      "English df len: 1738\n",
      "###### 0 ######\n",
      "Train df len: 4458\n",
      "Valid df len: 348\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd63f115f6f6459ab845aa69fdc237e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4458 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc7c2ade3cee4f9ba903e2a954a0ca5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/348 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9086218a2f724f4487b7b9469c9c6d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/892 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/anaconda/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-bcaa44dbc066>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mtrainDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'torch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ground_truth\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mvalidMetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidMetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-520ea1c09ea3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(trainDataset, validDataset)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;31m#send batch info through model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mpred1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0;31m#pred1, pred2 = pred1.unsqueeze(0), pred2.unsqueeze(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-aec6d47f26a4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mpred1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGELU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeanPooled1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mencoding2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m#all token embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mmeanPooled2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_pooling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    851\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         )\n\u001b[0;32m--> 853\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    854\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    525\u001b[0m                 )\n\u001b[1;32m    526\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    528\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    455\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         )\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#time how long it takes \n",
    "st = time.time()\n",
    "\n",
    "metrics = []\n",
    "transformers.logging.set_verbosity_error()\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "#JUST FOR TESTING \n",
    "#leanDf = leanDf[:300]\n",
    "\n",
    "#we only want to sample validation data from the pairs that are both english \n",
    "enDf = leanDf[(leanDf[\"url1_lang\"] == \"en\") & (leanDf[\"url2_lang\"] == \"en\")]\n",
    "\n",
    "print(\"Total df len: \" +  str(len(leanDf)))\n",
    "print(\"English df len: \" +  str(len(enDf)))\n",
    "#we create splits based on the position (not the actual index) of rows in enDf\n",
    "#the idea is to get a split of the english dataset to set aside and then \n",
    "#grab everything else in the en + translated dataset to train on \n",
    "for i, (train_index, valid_index) in enumerate(kf.split(enDf)): \n",
    "    \n",
    "    #grab the rows in enDf corresponding to the positions of our split \n",
    "    validDf = enDf.iloc[valid_index]\n",
    "    \n",
    "    #now get the actual indicies that have been selected\n",
    "    #and subtract the indices in trainDf away from those \n",
    "    remainingIndices = list(set(leanDf.index) - set(validDf.index))\n",
    "    trainDf = leanDf.loc[remainingIndices]\n",
    "    print(\"###### \" + str(i).upper() + \" ######\")\n",
    "    print(\"Train df len: \" + str(len(trainDf)))\n",
    "    print(\"Valid df len: \" + str(len(validDf)))\n",
    "    \n",
    "    #get data loaded in properly \n",
    "    trainDataset = Dataset.from_pandas(trainDf)\n",
    "    validDataset = Dataset.from_pandas(validDf)\n",
    "    \n",
    "    \n",
    "    trainDataset = trainDataset.map(lambda x: tokenizer(x[\"text1Merged\"], x[\"text2Merged\"], max_length=512, padding=\"max_length\", truncation=True))\n",
    "    validDataset = validDataset.map(lambda x: tokenizer(x[\"text1Merged\"], x[\"text2Merged\"], max_length=512, padding=\"max_length\", truncation=True))\n",
    "\n",
    "    #only need the input information \n",
    "    trainDataset = trainDataset.remove_columns([\"text1Merged\", \"text2Merged\", \"__index_level_0__\"])\n",
    "    validDataset = validDataset.remove_columns([\"text1Merged\", \"text2Merged\", \"__index_level_0__\"])\n",
    "\n",
    "    # convert dataset features to PyTorch tensors\n",
    "    validDataset.set_format(type='torch', columns=[\"ground_truth\", \"input_ids\", \"attention_mask\"])\n",
    "    trainDataset.set_format(type='torch', columns=[\"ground_truth\", \"input_ids\", \"attention_mask\"])\n",
    "\n",
    "    validMetrics = train(trainDataset, validDataset)\n",
    "    metrics.append(validMetrics)\n",
    "    \n",
    "    del trainDataset\n",
    "    del validDataset\n",
    "    \n",
    "\n",
    "et = time.time()\n",
    "elapsed = et - st\n",
    "print(\"ELAPSED TIME\")\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to an output folder \n",
    "import pickle \n",
    "with open(RESULTS_PATH + \"/outputData.pkl\", \"wb\") as f: \n",
    "    pickle.dump(metrics, f)\n",
    "    \n",
    "with open(RESULTS_PATH + \"/time.pkl\", \"wb\") as f: \n",
    "    pickle.dump(elapsed, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
