{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dc74c79-db1a-4d76-86b8-3e1778067044",
   "metadata": {},
   "source": [
    "create simple model draft to get outlet embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ca03ba7-ea94-4313-9f25-96acb2b1bdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "from torchmetrics.functional.classification import f1_score\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.model_selection import KFold\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datasets import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers.optimization import get_linear_schedule_with_warmup\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm \n",
    "import random\n",
    "import wandb \n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "551ed59c-fe2c-4d29-92ea-318a8c63fab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PROP = .7 \n",
    "VALID_PROP = .2\n",
    "TEST_PROP = .1\n",
    "\n",
    "TRAIN_NUM = int(TRAIN_PROP * len(allClusts)) \n",
    "VALID_NUM = int(VALID_PROP * len(allClusts)) \n",
    "TEST_NUM = int(len(allClusts) - (TRAIN_NUM + VALID_NUM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ccbd25c-87bb-4dd7-bf77-4a3f245e2199",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-e2098ce75a41>:2: DtypeWarning: Columns (2,3,10,11,13,14,17,39,40,41) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"/shared/3/projects/newsDiffusion/data/processed/fullDataWithClustNums.tsv\", sep=\"\\t\")\n"
     ]
    }
   ],
   "source": [
    "# load in the news data of interest \n",
    "df = pd.read_csv(\"/shared/3/projects/newsDiffusion/data/processed/fullDataWithClustNums.tsv\", sep=\"\\t\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71fd96fa-b4e8-469a-b0f2-b0878f6a0e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PICKLE_PATH = \"/shared/3/projects/newsDiffusion/data/processed/IRTmodel/storyEmbeddingsMean.pkl\"\n",
    "storyEmbeddings = pd.read_pickle(PICKLE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d888dc7e-0ae0-415a-ac2f-5def0566cfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we give a story cluster number and get back the average embedding for that story cluster \n",
    "storyDict = storyEmbeddings.set_index(\"clustNum\")[[\"storyMean\"]].to_dict()[\"storyMean\"] \n",
    "\n",
    "#we want to get a list of all possible story clusters that an outlet can cover\n",
    "allClusts = storyEmbeddings[\"clustNum\"].tolist()\n",
    "\n",
    "#keep only the articles that we have embeddings for, since we removed some clusters above\n",
    "outletStoryDf = df.loc[df[\"clustNum\"].isin(allClusts), [\"source\", \"clustNum\"]]\n",
    "\n",
    "#now we have each outlet and stories it covered \n",
    "outletStoryDf = outletStoryDf.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "804b8724-80d9-4279-b94d-61ad243c65d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainValid, testStories = train_test_split(allClusts, train_size=TRAIN_NUM + VALID_NUM, test_size=TEST_NUM)\n",
    "trainStories, validStories = train_test_split(trainValid, train_size=TRAIN_NUM, test_size=VALID_NUM) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "895011f8-588c-448e-bd2d-912865c5e350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainStories) == TRAIN_NUM \n",
    "len(testStories) == TEST_NUM \n",
    "len(validStories) == VALID_NUM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "013b94c4-5e1c-4c03-b30c-1d37c1f60ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf = outletStoryDf.loc[outletStoryDf[\"clustNum\"].isin(trainStories)]\n",
    "validDf = outletStoryDf.loc[outletStoryDf[\"clustNum\"].isin(validStories)]\n",
    "testDf = outletStoryDf.loc[outletStoryDf[\"clustNum\"].isin(testStories)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d8c11940-3429-4bfb-8343-0b8e5d7320a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify that rows in all of the train, test, valid sets \n",
    "#equals all of the rows before splitting up  \n",
    "len(trainDf) + len(validDf) + len(testDf) == len(outletStoryDf)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fd9285db-1b46-4a3c-a6b5-f33d6bebc22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#create dataframe from samples of not covered stories \\nnotCoveredDf = pd.DataFrame(notCoveredSamples, columns=[\"source\", \"clustNum\"])\\nnotCoveredDf[\"covered\"] = 0\\n\\n#get covered/non-covered stories in long form \\nclusteredStories = clusteredStories.reset_index().explode(\"clustNum\")\\nnotCoveredDf = notCoveredDf.explode(\"clustNum\") \\n\\n#merge both covered and not covered training examples \\n#a long form dataframe that gives us outlet, story cluster num, covered or not\\nallCoverage = pd.concat([notCoveredDf.reset_index(drop=True), clusteredStories.reset_index(drop=True)],axis=0) \\n\\n# mix up the rows so that we have equal number of pos/neg training examples \\n# we reset index so we can troubleshoot cross val splits later on\\nallCoverage = allCoverage.sample(frac = 1).reset_index(drop=True)\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#create dataframe from samples of not covered stories \n",
    "notCoveredDf = pd.DataFrame(notCoveredSamples, columns=[\"source\", \"clustNum\"])\n",
    "notCoveredDf[\"covered\"] = 0\n",
    "\n",
    "#get covered/non-covered stories in long form \n",
    "clusteredStories = clusteredStories.reset_index().explode(\"clustNum\")\n",
    "notCoveredDf = notCoveredDf.explode(\"clustNum\") \n",
    "\n",
    "#merge both covered and not covered training examples \n",
    "#a long form dataframe that gives us outlet, story cluster num, covered or not\n",
    "allCoverage = pd.concat([notCoveredDf.reset_index(drop=True), clusteredStories.reset_index(drop=True)],axis=0) \n",
    "\n",
    "# mix up the rows so that we have equal number of pos/neg training examples \n",
    "# we reset index so we can troubleshoot cross val splits later on\n",
    "allCoverage = allCoverage.sample(frac = 1).reset_index(drop=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "759f9565-665f-449c-9424-479522641628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>clustNum</th>\n",
       "      <th>covered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thesun</td>\n",
       "      <td>11331.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>citybusiness</td>\n",
       "      <td>11458.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thesun</td>\n",
       "      <td>52870.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alternet</td>\n",
       "      <td>87847.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>climatechangedispatch</td>\n",
       "      <td>138791.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  source  clustNum  covered\n",
       "0                 thesun   11331.0        1\n",
       "1           citybusiness   11458.0        1\n",
       "2                 thesun   52870.0        0\n",
       "3               alternet   87847.0        0\n",
       "4  climatechangedispatch  138791.0        1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allCoverage.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17db627e-c354-4b4b-b744-a14f68967a3f",
   "metadata": {},
   "source": [
    "### beginning of code for model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6dd9b3c-ccb1-4b93-9b74-1a51d9ea1d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "deviceNum = 2\n",
    "device = torch.device(\"cuda:\" + str(deviceNum) if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9b5159ee-7873-421c-bdaa-02dc8dd456ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicModel(nn.Module):\n",
    "\n",
    "    def __init__(self, numEmbeddings, embeddingLen, storyDict):\n",
    "        super(BasicModel, self).__init__()\n",
    "        self.embeddings = nn.Embedding(numEmbeddings, embeddingLen)\n",
    "        self.storyDict = storyDict\n",
    "        self.ReLU = nn.ReLU()\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.Dropout = nn.Dropout()\n",
    "        \n",
    "        #NOTE: 768 is the length of the BERT story vectors  \n",
    "        self.linear1 = nn.Linear(embeddingLen * 768, 200)\n",
    "        self.linear2 = nn.Linear(200, 1) \n",
    "    \n",
    "    #input will be the indices of the embeddings \n",
    "    def forward(self, embedIds, storyVecIds):\n",
    "        #these are the outlet embeddings NOT the story embeddings \n",
    "        outletEmbeds = self.embeddings(embedIds) #.view((1, -1))\n",
    "        storyVecs = torch.tensor([self.storyDict[int(clustNum)] for clustNum in storyVecIds], dtype=torch.float32).to(device)\n",
    "        inTens = torch.concat((outletEmbeds, storyVecs), dim=1).to(device)\n",
    "              \n",
    "        out = self.ReLU(self.Dropout(self.linear1(inTens)))\n",
    "        out = self.linear2(out)\n",
    "        probs = self.Sigmoid(out)\n",
    "        return probs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a775182e-5d05-475f-87d1-4b5ff8c5533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_ROWS = 10000\n",
    "trainDf = trainDf.head(TOTAL_ROWS) \n",
    "dataset = Dataset.from_pandas(trainDf)\n",
    "#trainDataset, validDataset = random_split(dataset, [.9, .1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "898a3ad0-ed49-490a-9cf8-a83ffefa6194",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeds = nn.Embedding(len(outlets), 768)  # number of story clusters x length of BERT embeddings \n",
    "outlets = df[\"source\"].unique()\n",
    "outletDict = {outlets[i]:i for i in range(0, len(outlets))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c5668286-a9aa-436d-afee-a581dad65291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(validLoader): \n",
    "    #validation loop \n",
    "    allPreds = []\n",
    "    allGts = []\n",
    "    for batch in validLoader: \n",
    "        outletLookups = torch.tensor([outletDict[outlet] for outlet in batch[\"source\"]]).to(device)\n",
    "        preds = model(outletLookups, batch[\"clustNum\"].to(device))\n",
    "        gts = torch.unsqueeze(batch[\"covered\"], dim=1).to(device) \n",
    "        allPreds += preds.detach().squeeze().cpu().tolist()\n",
    "        allGts += gts.detach().squeeze().cpu().tolist()\n",
    "    return f1_score(torch.tensor(allPreds), torch.tensor(allGts)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0aef30a9-6fc8-4d4f-aac3-eefd414b87d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.BCELoss()\n",
    "\n",
    "GROUP_NAME=\"testSavingModel\" \n",
    "TRAIN_BATCH_SIZE=100\n",
    "VALID_BATCH_SIZE=200\n",
    "EPOCHS=1\n",
    "LR = .0001\n",
    "# testing out cross validation\n",
    "\n",
    "validTups = []\n",
    "trainTups = []\n",
    "\n",
    "K_FOLDS = 3\n",
    "kfold = KFold(n_splits=K_FOLDS, shuffle=True)\n",
    "config = {\n",
    "    \"lr\":LR,\n",
    "    \"batchSize\":TRAIN_BATCH_SIZE,\n",
    "    \"numFolds\":K_FOLDS, \n",
    "    \"totalExamples\":TOTAL_ROWS,\n",
    "    \"trainExamples\":TOTAL_ROWS * ((K_FOLDS - 1)/ K_FOLDS),\n",
    "    \"loss\":\"Binary Cross Entropy\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ee09f066-2a89-4b62-800f-e94ab016a9e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.18"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/shared/3/projects/newsDiffusion/models/IRTModelling/wandb/run-20230509_154505-tv2qmuk3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/blitt/localNews-notebooks_IRTModelling/runs/tv2qmuk3\" target=\"_blank\">lunar-serenity-25</a></strong> to <a href=\"https://wandb.ai/blitt/localNews-notebooks_IRTModelling\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:02<00:00, 22.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:tv2qmuk3) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>trainLoss</td><td>▇█▅▅▁▄▄</td></tr><tr><td>validF1</td><td>▁▂▄▆▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>trainLoss</td><td>0.69842</td></tr><tr><td>validF1</td><td>0.51916</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">lunar-serenity-25</strong>: <a href=\"https://wandb.ai/blitt/localNews-notebooks_IRTModelling/runs/tv2qmuk3\" target=\"_blank\">https://wandb.ai/blitt/localNews-notebooks_IRTModelling/runs/tv2qmuk3</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/shared/3/projects/newsDiffusion/models/IRTModelling/wandb/run-20230509_154505-tv2qmuk3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:tv2qmuk3). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.18"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/shared/3/projects/newsDiffusion/models/IRTModelling/wandb/run-20230509_154515-hppf0fm8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/blitt/localNews-notebooks_IRTModelling/runs/hppf0fm8\" target=\"_blank\">decent-breeze-26</a></strong> to <a href=\"https://wandb.ai/blitt/localNews-notebooks_IRTModelling\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:03<00:00, 21.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:hppf0fm8) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>trainLoss</td><td>▁██▄▄▃▆</td></tr><tr><td>validF1</td><td>█▅▂▁▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>trainLoss</td><td>0.7074</td></tr><tr><td>validF1</td><td>0.64916</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">decent-breeze-26</strong>: <a href=\"https://wandb.ai/blitt/localNews-notebooks_IRTModelling/runs/hppf0fm8\" target=\"_blank\">https://wandb.ai/blitt/localNews-notebooks_IRTModelling/runs/hppf0fm8</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/shared/3/projects/newsDiffusion/models/IRTModelling/wandb/run-20230509_154515-hppf0fm8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:hppf0fm8). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.18"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/shared/3/projects/newsDiffusion/models/IRTModelling/wandb/run-20230509_154533-3dgpaglm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/blitt/localNews-notebooks_IRTModelling/runs/3dgpaglm\" target=\"_blank\">hardy-star-27</a></strong> to <a href=\"https://wandb.ai/blitt/localNews-notebooks_IRTModelling\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:02<00:00, 22.74it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = BasicModel(len(outlets) , 768, storyDict) \n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "for EPOCH in range(EPOCHS):\n",
    "    #TODO: add in 0's to the data \n",
    "    trainDataset = Dataset.from_pandas(trainDf)\n",
    "    validDataset = Dataset.from_pandas(validDf)\n",
    "\n",
    "    trainLoader = DataLoader(trainDataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
    "    validLoader = DataLoader(validDataset, batch_size=VALID_BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    for batch in trainLoader: \n",
    "    #run = wandb.init(dir=\"/shared/3/projects/newsDiffusion/models/IRTModelling/\",reinit=True, config=config,group=GROUP_NAME)\n",
    "    \n",
    "    print(f\"fold: {fold}\")\n",
    "    \n",
    "    # and setup a warmup for the first ~10% steps\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "    total_steps = int((len(trainDataset) * EPOCHS) / TRAIN_BATCH_SIZE)\n",
    "    warmup_steps = int(0.1 * total_steps)\n",
    "    scheduler = get_linear_schedule_with_warmup(optim, num_warmup_steps=warmup_steps, num_training_steps=total_steps - warmup_steps)\n",
    "    \n",
    "    subLossList = []\n",
    "    i = 0 \n",
    "    for batch in tqdm(trainLoader): \n",
    "        model.train()\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        #get the outlet ids from the outlet names fed into lookup dictionary  \n",
    "        outletLookups = torch.tensor([outletDict[outlet] for outlet in batch[\"source\"]]).to(device)\n",
    "        preds = model(outletLookups, batch[\"clustNum\"].to(device))\n",
    "\n",
    "        #get ground truth labels from the batch \n",
    "        gts = torch.unsqueeze(batch[\"covered\"], dim=1).type(\"torch.FloatTensor\").to(device) \n",
    "\n",
    "        loss = loss_func(preds, gts)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        scheduler.step()\n",
    "        subLossList.append(loss.detach().item())\n",
    "        if i % 10 == 0:\n",
    "            model.eval()\n",
    "            trainLoss = np.mean(subLossList) \n",
    "            validF1 = validate(validLoader)\n",
    "            \n",
    "            #add to dataframe \n",
    "            validTups.append((fold, i, validF1))\n",
    "            trainTups.append((fold, i, trainLoss))\n",
    "            \n",
    "            #log to weights and biases \n",
    "            #wandb.log({\"trainLoss\":trainLoss, \"validF1\":validF1}) \n",
    "            subLossList = []\n",
    "            model.train()\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c52d8fb2-6dcd-48ea-a6bf-58530006133b",
   "metadata": {},
   "outputs": [],
   "source": [
    "validDf = pd.DataFrame(validTups, columns=[\"fold\", \"batch\", \"f1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8e71e2f8-bb01-4a48-b4db-16e940159b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "validDf[\"f1\"] = [item.item() for item in validDf[\"f1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "41e8d835-d832-41bf-8f55-e2fc3f0fccee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.,  2.,  7.,  9.,  9., 13., 10.,  8.,  4.,  2.]),\n",
       " array([0.41856572, 0.43840894, 0.45825216, 0.47809537, 0.49793859,\n",
       "        0.51778181, 0.53762503, 0.55746824, 0.57731146, 0.59715468,\n",
       "        0.6169979 ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(preds.squeeze().tolist()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "db25b5b7-1ffe-494a-87b4-919b717e4213",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainEvalDf = pd.DataFrame(trainTups, columns=[\"fold\", \"batch\", \"BCEloss\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "39e56eff-cd72-4d37-8e41-6ce0206d3dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.lineplot(x=\"batch\", y=\"f1\", hue=\"fold\", data=validDf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "90ad10e9-3655-4632-94bd-f7eed533e28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#sns.lineplot(x=\"batch\", y=\"BCEloss\", hue=\"fold\", data=trainEvalDf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9d0a281e-2416-48fa-b92f-81211440c65a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='6.049 MB of 6.049 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>trainLoss</td><td>█▁▃▂▃▃▂</td></tr><tr><td>validF1</td><td>▁▅▇██▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>trainLoss</td><td>0.69806</td></tr><tr><td>validF1</td><td>0.58697</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hardy-star-27</strong>: <a href=\"https://wandb.ai/blitt/localNews-notebooks_IRTModelling/runs/3dgpaglm\" target=\"_blank\">https://wandb.ai/blitt/localNews-notebooks_IRTModelling/runs/3dgpaglm</a><br/>Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/shared/3/projects/newsDiffusion/models/IRTModelling/wandb/run-20230509_154533-3dgpaglm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_STEM = \"basicModel\" \n",
    "OUT_STEM = \"/shared/3/projects/newsDiffusion/models/IRTModelling/savedModels/outletEmbeddingsModel/\" + MODEL_STEM \n",
    "\n",
    "#save data related to best model \n",
    "torch.save(model.state_dict(), OUT_STEM + \".pth\") \n",
    "artifact = wandb.Artifact(MODEL_STEM, type=\"model\") \n",
    "artifact.add_file(OUT_STEM + \".pth\") \n",
    "run.log_artifact(artifact)\n",
    "\n",
    "#save embeddings \n",
    "finalOutletEmbeddings = np.array(model.embeddings.weight.data.cpu())\n",
    "\n",
    "with open(OUT_STEM + \"Embeddings.arr\", \"wb\") as embedsFile:  \n",
    "    pickle.dump(finalOutletEmbeddings, embedsFile)\n",
    "\n",
    "artifact = wandb.Artifact(MODEL_STEM + \"Embeddings\", type=\"embeddings\") \n",
    "artifact.add_file(OUT_STEM + \"Embeddings.arr\") \n",
    "run.log_artifact(artifact)\n",
    "\n",
    "#save dict mapping embeddings to outlet names\n",
    "with open(OUT_STEM + \"EmbeddingsDict.dict\", \"wb\") as dictFile: \n",
    "    pickle.dump(outletDict, dictFile)\n",
    "\n",
    "artifact = wandb.Artifact(MODEL_STEM + \"EmbeddingsDict\", type=\"dict\") \n",
    "artifact.add_file(OUT_STEM + \"EmbeddingsDict.dict\") \n",
    "run.log_artifact(artifact)\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d3826a-6153-4adc-bded-522baeccc722",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
