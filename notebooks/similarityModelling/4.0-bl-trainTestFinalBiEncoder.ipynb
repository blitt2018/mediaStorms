{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch \n",
    "import transformers\n",
    "from transformers import PreTrainedTokenizer\n",
    "from transformers import RobertaTokenizer, PreTrainedTokenizer, DistilBertTokenizer, DistilBertModel, RobertaModel\n",
    "from sentence_transformers import SentenceTransformer, SentencesDataset, InputExample, losses, util\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from transformers.optimization import get_linear_schedule_with_warmup\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.nn import CosineEmbeddingLoss\n",
    "import random\n",
    "from torch.nn import CosineEmbeddingLoss\n",
    "from torch import nn\n",
    "#Build up to SBERT model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "deviceNum = 0\n",
    "device = torch.device(\"cuda:\" + str(deviceNum) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "GRAD_ACC = 6\n",
    "EPOCHS = 1\n",
    "FOLDS = 5\n",
    "SEED = 85\n",
    "BATCH_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get training data \n",
    "df = pd.read_csv(\"/shared/3/projects/newsDiffusion/data/processed/translated_288_96.tsv\", sep=\"\\t\", nrows=100)\n",
    "\n",
    "#put ground truth values into a list \n",
    "df[\"ground_truth\"] = df['Overall']\n",
    "\n",
    "#quirk from reusing code \n",
    "leanDf = df\n",
    "\n",
    "#rescale data from (0, 4): (0, 1)\n",
    "leanDf[\"ground_truth\"] = 1 - ((leanDf[\"ground_truth\"] - 1) / 3)\n",
    "\n",
    "#reset index so it is contiguous set of numbers \n",
    "leanDf = leanDf.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([35., 12.,  7.,  5.,  5.,  7.,  7.,  4.,  9.,  9.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAOCklEQVR4nO3df6zd9V3H8edrFDIUIsVeSAPUTsQ5skjBayWiC4NNC/sDSLZENNAsJMU4DEv4Y4Q/HIv/sGQMY5zMMgjVzC1EmODGpg0OkYwfXpZSit0EERHW0MvYBGYy0/L2j/OtaS73cr6958ftZ30+kpt7zvd8T8/7kzZPDt/7/Z6bqkKS1J53rPQAkqTlMeCS1CgDLkmNMuCS1CgDLkmNWjXNF1uzZk2tX79+mi8pSc174oknXqmqmYXbpxrw9evXMzc3N82XlKTmJfnPxbZ7CEWSGmXAJalRBlySGmXAJalRBlySGmXAJalRQwOe5J1JHk/yZJKnk3yq235jkpeS7Oi+Lp78uJKkA/qcB/5j4IKqeiPJ0cDDSb7ePXZLVX1mcuNJkpYyNOA1+MDwN7q7R3dffoi4JK2wXldiJjkKeAL4BeBzVfVYkouAa5JcCcwB11XVDxZ57hZgC8C6deuWPej667+27OeO6vmbPrRiry1JS+n1Q8yq2l9VG4BTgY1J3gvcCpwObAD2ADcv8dytVTVbVbMzM2+5lF+StEyHdBZKVf0QeBDYVFUvd2F/E7gN2Dj+8SRJS+lzFspMkhO628cCHwC+k2TtQbtdBuyayISSpEX1OQa+FtjWHQd/B3BXVX01yV8l2cDgB5rPA1dPbEpJ0lv0OQtlJ3D2ItuvmMhEkqRevBJTkhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckhplwCWpUUMDnuSdSR5P8mSSp5N8qtt+YpLtSZ7pvq+e/LiSpAP6vAP/MXBBVZ0FbAA2JTkXuB54oKrOAB7o7kuSpmRowGvgje7u0d1XAZcA27rt24BLJzGgJGlxvY6BJzkqyQ5gL7C9qh4DTq6qPQDd95OWeO6WJHNJ5ubn58c0tiSpV8Cran9VbQBOBTYmeW/fF6iqrVU1W1WzMzMzyxxTkrTQIZ2FUlU/BB4ENgEvJ1kL0H3fO+7hJElL63MWykySE7rbxwIfAL4D3Ads7nbbDNw7oRklSYtY1WOftcC2JEcxCP5dVfXVJI8AdyW5CngB+MgE55QkLTA04FW1Ezh7ke3fBy6cxFCSpOG8ElOSGmXAJalRBlySGmXAJalRBlySGmXAJalRBlySGmXAJalRBlySGmXAJalRBlySGmXAJalRBlySGmXAJalRBlySGmXAJalRBlySGmXAJalRBlySGmXAJalRBlySGjU04ElOS/LNJLuTPJ3k2m77jUleSrKj+7p48uNKkg5Y1WOffcB1VfXtJMcDTyTZ3j12S1V9ZnLjSZKWMjTgVbUH2NPdfj3JbuCUSQ8mSXp7h3QMPMl64GzgsW7TNUl2JrkjyeolnrMlyVySufn5+dGmlST9v94BT3IccDfw8ap6DbgVOB3YwOAd+s2LPa+qtlbVbFXNzszMjD6xJAnoGfAkRzOI9xer6h6Aqnq5qvZX1ZvAbcDGyY0pSVqoz1koAW4HdlfVZw/avvag3S4Ddo1/PEnSUvqchXIecAXwVJId3bYbgMuTbAAKeB64egLzSZKW0OcslIeBLPLQ/eMfR5LUl1diSlKjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNWpowJOcluSbSXYneTrJtd32E5NsT/JM93315MeVJB3Q5x34PuC6qnoPcC7wsSRnAtcDD1TVGcAD3X1J0pQMDXhV7amqb3e3Xwd2A6cAlwDbut22AZdOaEZJ0iIO6Rh4kvXA2cBjwMlVtQcGkQdOWuI5W5LMJZmbn58fcVxJ0gG9A57kOOBu4ONV9Vrf51XV1qqararZmZmZ5cwoSVpEr4AnOZpBvL9YVfd0m19OsrZ7fC2wdzIjSpIW0+cslAC3A7ur6rMHPXQfsLm7vRm4d/zjSZKWsqrHPucBVwBPJdnRbbsBuAm4K8lVwAvARyYyoSRpUUMDXlUPA1ni4QvHO44kqS+vxJSkRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRg0NeJI7kuxNsuugbTcmeSnJju7r4smOKUlaqM878DuBTYtsv6WqNnRf9493LEnSMEMDXlUPAa9OYRZJ0iEY5Rj4NUl2dodYVi+1U5ItSeaSzM3Pz4/wcpKkgy034LcCpwMbgD3AzUvtWFVbq2q2qmZnZmaW+XKSpIWWFfCqermq9lfVm8BtwMbxjiVJGmZZAU+y9qC7lwG7ltpXkjQZq4btkORLwPnAmiQvAp8Ezk+yASjgeeDqyY0oSVrM0IBX1eWLbL59ArNIkg6BV2JKUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1auiHWQnWX/+1FXnd52/60Iq8rqQ2+A5ckhplwCWpUQZckhplwCWpUQZckhplwCWpUQZckho1NOBJ7kiyN8mug7admGR7kme676snO6YkaaE+78DvBDYt2HY98EBVnQE80N2XJE3R0IBX1UPAqws2XwJs625vAy4d71iSpGGWewz85KraA9B9P2l8I0mS+pj4DzGTbEkyl2Rufn5+0i8nSUeM5Qb85SRrAbrve5fasaq2VtVsVc3OzMws8+UkSQstN+D3AZu725uBe8czjiSprz6nEX4JeAR4d5IXk1wF3AR8MMkzwAe7+5KkKRr6eeBVdfkSD1045lkkSYfAKzElqVH+Rh5JU7dSv+VqJU3iN2z5DlySGmXAJalRBlySGmXAJalRBlySGmXAJalRBlySGmXAJalRBlySGmXAJalRXkp/GFupy40nccnv4c5Lu9Ui34FLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1aqQLeZI8D7wO7Af2VdXsOIaSJA03jisx319Vr4zhz5EkHQIPoUhSo0Z9B17APyQp4C+qauvCHZJsAbYArFu3bsSX0zQciZ8LIrVo1Hfg51XVOcBFwMeSvG/hDlW1tapmq2p2ZmZmxJeTJB0wUsCr6nvd973AV4CN4xhKkjTcsgOe5KeTHH/gNvBbwK5xDSZJenujHAM/GfhKkgN/zl9X1TfGMpUkaahlB7yqngPOGuMskqRD4G/kkY5Qnm3UPs8Dl6RGGXBJapQBl6RGGXBJapQBl6RGGXBJapQBl6RGGXBJapQBl6RGGXBJapQBl6RGGXBJapQBl6RGGXBJapQBl6RGGXBJapQBl6RGGXBJapQBl6RGGXBJatRIAU+yKcl3kzyb5PpxDSVJGm7ZAU9yFPA54CLgTODyJGeOazBJ0tsb5R34RuDZqnquqv4X+DJwyXjGkiQNs2qE554C/NdB918Efm3hTkm2AFu6u28k+e4yX28N8Moyn9sq13xkcM1HgHx6pDX/3GIbRwl4FtlWb9lQtRXYOsLrDF4smauq2VH/nJa45iODaz4yTGLNoxxCeRE47aD7pwLfG20cSVJfowT8X4AzkrwryTHA7wD3jWcsSdIwyz6EUlX7klwD/D1wFHBHVT09tsneauTDMA1yzUcG13xkGPuaU/WWw9aSpAZ4JaYkNcqAS1KjDruAD7s8PwN/2j2+M8k5KzHnOPVY8+91a92Z5FtJzlqJOcep78cwJPnVJPuTfHia841bn/UmOT/JjiRPJ/mnac84bj3+Xf9Mkr9L8mS35o+uxJzjlOSOJHuT7Fri8fH2q6oOmy8GPwz9d+DngWOAJ4EzF+xzMfB1Buehnws8ttJzT2HNvw6s7m5fdCSs+aD9/hG4H/jwSs894b/jE4B/BdZ1909a6bmnsOYbgE93t2eAV4FjVnr2Edf9PuAcYNcSj4+1X4fbO/A+l+dfAvxlDTwKnJBk7bQHHaOha66qb1XVD7q7jzI4575lfT+G4Q+Bu4G90xxuAvqs93eBe6rqBYCqOhLWXMDxSQIcxyDg+6Y75nhV1UMM1rGUsfbrcAv4Ypfnn7KMfVpyqOu5isF/wVs2dM1JTgEuAz4/xbkmpc/f8S8Cq5M8mOSJJFdObbrJ6LPmPwPew+ACwKeAa6vqzemMt2LG2q9RLqWfhD6X5/e6hL8hvdeT5P0MAv4bE51o8vqs+U+AT1TV/sEbtKb1We8q4FeAC4FjgUeSPFpV/zbp4Sakz5p/G9gBXACcDmxP8s9V9dqEZ1tJY+3X4RbwPpfn/6Rdwt9rPUl+GfgCcFFVfX9Ks01KnzXPAl/u4r0GuDjJvqr626lMOF59/12/UlU/An6U5CHgLKDVgPdZ80eBm2pwcPjZJP8B/BLw+HRGXBFj7dfhdgilz+X59wFXdj/NPRf476raM+1Bx2jompOsA+4Brmj4HdnBhq65qt5VVeuraj3wN8AfNBpv6Pfv+l7gN5OsSvJTDD7Zc/eU5xynPmt+gcH/cZDkZODdwHNTnXL6xtqvw+odeC1xeX6S3+8e/zyDMxIuBp4F/ofBf8Wb1XPNfwT8LPDn3TvSfdXwJ7n1XPNPjD7rrardSb4B7ATeBL5QVYueitaCnn/HfwzcmeQpBocWPlFVTX/EbJIvAecDa5K8CHwSOBom0y8vpZekRh1uh1AkST0ZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEb9H2tcmFTOpbMlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(leanDf[\"ground_truth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get test data \n",
    "#this is the test data that has already had the \n",
    "#title concatenated and the head + tail merged\n",
    "testDf = pd.read_csv(\"/shared/3/projects/newsDiffusion/data/processed/enTestTranslated_288_96.tsv\", sep=\"\\t\")\n",
    "\n",
    "testDf[\"ground_truth\"] = testDf[\"Overall\"]\n",
    "\n",
    "#rescale ground truth to be between zero and one\n",
    "#testDf[\"ground_truth\"] = 1 - ((testDf[\"ground_truth\"] - 1) / 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([96.,  7.,  0., 30.,  1.,  8., 34.,  2.,  8., 50.]),\n",
       " array([1. , 1.3, 1.6, 1.9, 2.2, 2.5, 2.8, 3.1, 3.4, 3.7, 4. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(testDf[\"ground_truth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiModel(nn.Module): \n",
    "    def __init__(self):\n",
    "        super(BiModel,self).__init__()\n",
    "        print(torch.seed())\n",
    "        self.model = AutoModel.from_pretrained('sentence-transformers/all-mpnet-base-v2').to(device).train()\n",
    "        self.cos = torch.nn.CosineSimilarity(dim=1, eps=1e-4)\n",
    "        \n",
    "    def mean_pooling(self, token_embeddings, attention_mask): \n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask): \n",
    "        \n",
    "        input_ids_a = input_ids[0].to(device)\n",
    "        input_ids_b = input_ids[1].to(device)\n",
    "        attention_a = attention_mask[0].to(device)\n",
    "        attention_b = attention_mask[1].to(device)\n",
    "        \n",
    "        #encode sentence and get mean pooled sentence representation \n",
    "        encoding1 = self.model(input_ids_a, attention_mask=attention_a)[0] #all token embeddings\n",
    "        encoding2 = self.model(input_ids_b, attention_mask=attention_b)[0]\n",
    "        \n",
    "        meanPooled1 = self.mean_pooling(encoding1, attention_a)\n",
    "        meanPooled2 = self.mean_pooling(encoding2, attention_b)\n",
    "        \n",
    "        pred = self.cos(meanPooled1, meanPooled2)\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainBi(trainDataset): \n",
    "    print(torch.seed())\n",
    "    model = BiModel().to(device)\n",
    "    \n",
    "    # we would initialize everything first\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=2e-6)\n",
    "    \n",
    "    # and setup a warmup for the first ~10% steps\n",
    "    total_steps = int(len(trainDataset) / BATCH_SIZE)*EPOCHS\n",
    "    warmup_steps = int(0.1 * total_steps)\n",
    "    scheduler = get_linear_schedule_with_warmup(optim, num_warmup_steps=warmup_steps, num_training_steps=total_steps - warmup_steps)\n",
    "\n",
    "    loss_func = torch.nn.MSELoss(reduction=\"mean\")\n",
    "\n",
    "    trainLoader = torch.utils.data.DataLoader(trainDataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        print(\"EPOCH: \" + str(epoch))\n",
    "        \n",
    "        model.train()  # make sure model is in training mode\n",
    "\n",
    "        for batch in tqdm(trainLoader):\n",
    "            optim.zero_grad()\n",
    "            \n",
    "            input_ids = [batch[\"text1Merged_input_ids\"], batch[\"text2Merged_input_ids\"]]\n",
    "            attention_masks = [batch[\"text1Merged_attention_mask\"], batch[\"text2Merged_attention_mask\"]]\n",
    "            pred = model(input_ids, attention_masks)\n",
    "            \n",
    "            gt = batch[\"ground_truth\"].to(device)\n",
    "            loss = loss_func(pred, gt)\n",
    "            \n",
    "            # using loss, calculate gradients and then optimize\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07511eb5bf164de3beddf10c2c871185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/236 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee8898e2ca84496e87455f53eef254d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/236 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load in our test data \n",
    "testDataset = Dataset.from_pandas(testDf[[\"text1Merged\", \"text2Merged\"]])\n",
    "\n",
    "#tokenizer\n",
    "biTokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "all_cols = []\n",
    "for part in [\"text1Merged\", \"text2Merged\"]: \n",
    "    #tokenizes each row of the dataset and gives us back tuple of lists \n",
    "    testDataset = testDataset.map(lambda x: biTokenizer(x[part], max_length=384, padding=\"max_length\", truncation=True))\n",
    "\n",
    "    for col in ['input_ids', 'attention_mask']: \n",
    "        testDataset = testDataset.rename_column(col, part+'_'+col)\n",
    "        all_cols.append(part+'_'+col)\n",
    "\n",
    "testDataset.set_format(type='torch', columns=all_cols)\n",
    "\n",
    "def testModel(trainedModel, testDataset): \n",
    "    testLoader = torch.utils.data.DataLoader(testDataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    simList = []\n",
    "    for i, batch in tqdm(enumerate(testLoader)): \n",
    "        ids = [batch[\"text1Merged_input_ids\"],batch[\"text2Merged_input_ids\"]]\n",
    "        masks = [batch[\"text1Merged_attention_mask\"],batch[\"text2Merged_attention_mask\"]]\n",
    "        sim = trainedModel(ids, masks)\n",
    "        simList += sim.detach().cpu().tolist()\n",
    "    \n",
    "    \n",
    "    testDf[\"sims\"] = simList\n",
    "    testDf[\"scaledSims\"] = (3*(1-testDf[\"sims\"])) + 1\n",
    "    \n",
    "    corrMat = np.corrcoef(testDf[\"ground_truth\"], testDf[\"scaledSims\"])\n",
    "    corr = corrMat[0, 1]\n",
    "    print(corr)\n",
    "    return [corr, testDf, corrMat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train df len: 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79ff94dc8b4846e89ef8942dd061360e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce8ea1b386b4f07b2aca89a445a5e4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9985177244475411874\n",
      "8478962953745225685\n",
      "EPOCH: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3ed4410f159403e9a815ca6d00de274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352d8aeb8c4647a6b6a1ad2be77775d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8238620611982242\n",
      "Train df len: 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb0f17316664b5788d4e3095913d0e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "854c758018bc48c3bf7dc12e66fd4269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587418569573560914\n",
      "472571253582557449\n",
      "EPOCH: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2458c915d31e4138a99710fb98ce8663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46c216d0a8a34c848594fcbece4c05fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8254846657048992\n",
      "Train df len: 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8499cca73ddf450798898ac435fc4e96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "797c8b48c85545428a0fbe1100e3cb3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14636926035914310847\n",
      "2186919020913630768\n",
      "EPOCH: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "742bc8b35d3b4f18bea1fa836067b1df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭──────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;ipython-input-13-905773ec7ec1&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">31</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;ipython-input-11-4247d610762b&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">33</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">trainBi</span>                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/anaconda/lib/python3.9/site-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_tensor.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">401</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 398 │   │   │   │   </span>retain_graph=retain_graph,                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 399 │   │   │   │   </span>create_graph=create_graph,                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 400 │   │   │   │   </span>inputs=inputs)                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 401 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>torch.autograd.backward(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, gradient, retain_graph, create_graph, inputs <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 402 │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 403 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">register_hook</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, hook):                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 404 │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">r\"\"\"Registers a backward hook.</span>                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/anaconda/lib/python3.9/site-packages/torch/autograd/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">__init__.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">191</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">188 │   # The reason we repeat same the comment below is that</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">189 │   # some Python versions print out the first line of a multi-line function</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">190 │   # calls in the traceback and some print out the last line</span>                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>191 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>Variable._execution_engine.run_backward(  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Calls into the C++ engine to run th</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">192 │   │   </span>tensors, grad_tensors_, retain_graph, create_graph, inputs,                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">193 │   │   </span>allow_unreachable=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>, accumulate_grad=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Calls into the C++ engine </span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">194 </span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰───────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m─────────────────────────── \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m ───────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33m<ipython-input-13-905773ec7ec1>\u001b[0m:\u001b[94m31\u001b[0m in \u001b[92m<module>\u001b[0m                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33m<ipython-input-11-4247d610762b>\u001b[0m:\u001b[94m33\u001b[0m in \u001b[92mtrainBi\u001b[0m                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/anaconda/lib/python3.9/site-packages/torch/\u001b[0m\u001b[1;33m_tensor.py\u001b[0m:\u001b[94m401\u001b[0m in \u001b[92mbackward\u001b[0m                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 398 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mretain_graph=retain_graph,                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 399 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mcreate_graph=create_graph,                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 400 \u001b[0m\u001b[2m│   │   │   │   \u001b[0minputs=inputs)                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 401 \u001b[2m│   │   \u001b[0mtorch.autograd.backward(\u001b[96mself\u001b[0m, gradient, retain_graph, create_graph, inputs \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 402 \u001b[0m\u001b[2m│   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 403 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mregister_hook\u001b[0m(\u001b[96mself\u001b[0m, hook):                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 404 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[33mr\u001b[0m\u001b[33m\"\"\"Registers a backward hook.\u001b[0m                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/anaconda/lib/python3.9/site-packages/torch/autograd/\u001b[0m\u001b[1;33m__init__.py\u001b[0m:\u001b[94m191\u001b[0m in \u001b[92mbackward\u001b[0m      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m188 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# The reason we repeat same the comment below is that\u001b[0m                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m189 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# some Python versions print out the first line of a multi-line function\u001b[0m        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m190 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# calls in the traceback and some print out the last line\u001b[0m                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m191 \u001b[2m│   \u001b[0mVariable._execution_engine.run_backward(  \u001b[2m# Calls into the C++ engine to run th\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m192 \u001b[0m\u001b[2m│   │   \u001b[0mtensors, grad_tensors_, retain_graph, create_graph, inputs,                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m193 \u001b[0m\u001b[2m│   │   \u001b[0mallow_unreachable=\u001b[94mTrue\u001b[0m, accumulate_grad=\u001b[94mTrue\u001b[0m)  \u001b[2m# Calls into the C++ engine \u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m194 \u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰───────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_OUTPUT_STEM = \"/shared/3/projects/newsDiffusion/models/2.0-biModelAblation/finalModel/\"\n",
    "\n",
    "seedList = [85, 92, 200, 135, 60]\n",
    "finalCorrs = {}\n",
    "\n",
    "for seed in seedList:\n",
    "    \n",
    "    #set seeds \n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    #get tokenizer. This is done in the loop so we have random ordering\n",
    "    transformers.logging.set_verbosity_error()\n",
    "    biTokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "    print(\"Train df len: \" +  str(len(leanDf)))\n",
    "\n",
    "    trainDataset = Dataset.from_pandas(leanDf)\n",
    "\n",
    "    all_cols = [\"ground_truth\"]\n",
    "    #NOTE: here we use the merged text\n",
    "    for part in [\"text1Merged\", \"text2Merged\"]: \n",
    "        #tokenizes each row of the dataset and gives us back tuple of lists \n",
    "        trainDataset = trainDataset.map(lambda x: biTokenizer(x[part], max_length=384, padding=\"max_length\", truncation=True))\n",
    "\n",
    "        for col in ['input_ids', 'attention_mask']: \n",
    "            trainDataset = trainDataset.rename_column(col, part+'_'+col)\n",
    "            all_cols.append(part+'_'+col)\n",
    "\n",
    "    trainDataset.set_format(type='torch', columns=all_cols)\n",
    "    trainedModel = trainBi(trainDataset)\n",
    "    finalCorrs[seed] = testModel(trainedModel, testDataset)[0]\n",
    "    \n",
    "    #save this trained model. We will use the best one in the pipeline \n",
    "    torch.save(trainedModel.state_dict(), MODEL_OUTPUT_STEM + str(seed) + \"/state_dict.tar\")\n",
    "    \n",
    "    #just for memory purposes \n",
    "    del trainedModel \n",
    "    del trainDataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭──────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;ipython-input-14-16bccb9d9752&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰───────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'trainedModel'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m─────────────────────────── \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m ───────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33m<ipython-input-14-16bccb9d9752>\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰───────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'trainedModel'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr, testDf, corrMat = testModel(trainedModel, testDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1714.,  263.,  132.,  799.,   95.,  145.,  717.,   89.,  143.,\n",
       "         853.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(leanDf[\"ground_truth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([96.,  7.,  0., 30.,  1.,  8., 34.,  2.,  8., 50.]),\n",
       " array([1. , 1.3, 1.6, 1.9, 2.2, 2.5, 2.8, 3.1, 3.4, 3.7, 4. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(testDf[\"ground_truth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDf[\"simsScaled\"] = (3*(1-testDf[\"sims\"])) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.85752434],\n",
       "       [0.85752434, 1.        ]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(testDf[\"simsScaled\"], testDf[\"ground_truth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      3.5\n",
       "1      1.0\n",
       "2      4.0\n",
       "3      1.5\n",
       "4      4.0\n",
       "      ... \n",
       "231    4.0\n",
       "232    1.0\n",
       "233    2.0\n",
       "234    2.0\n",
       "235    1.0\n",
       "Name: ground_truth, Length: 236, dtype: float64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDf[\"ground_truth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to an output folder \n",
    "RESULTS_PATH = \"/shared/3/projects/newsDiffusion/models/2.0-biModelAblation/finalModel/\"\n",
    "\n",
    "import pickle \n",
    "with open(RESULTS_PATH + \"modelResults.pkl\", \"wb\") as f: \n",
    "    pickle.dump(finalCorrs, f)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
