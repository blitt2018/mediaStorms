{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News Article Similarity Modelling\n",
    "- Cross encoding \n",
    "- Translated data \n",
    "- Using Title "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch \n",
    "import random\n",
    "from torch import nn\n",
    "from transformers import RobertaTokenizer, PreTrainedTokenizer, DistilBertTokenizer, DistilBertModel, RobertaModel\n",
    "from sentence_transformers import SentenceTransformer, SentencesDataset, InputExample, losses\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from transformers.optimization import get_linear_schedule_with_warmup\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.nn import CosineEmbeddingLoss\n",
    "import transformers\n",
    "import pickle \n",
    "import time\n",
    "#Build up to SBERT model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE_NUM = 2\n",
    "BATCH_SIZE = 5\n",
    "EPOCHS = 3\n",
    "SEED = 85\n",
    "FOLDS = 5\n",
    "RDROP_WEIGHT = .1\n",
    "FORWARD_WEIGHT = (1 - RDROP_WEIGHT) / 2\n",
    "\n",
    "device = torch.device(\"cuda:\" + str(DEVICE_NUM) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "RESULTS_PATH = \"/home/blitt/projects/localNews/models/sentEmbeddings/3.0-crossModelAblation/finalModel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set seeds \n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"/shared/3/projects/benlitterer/localNews/NetworkMVP/translatedCleaned.tsv\", sep=\"\\t\")\n",
    "df = pd.read_csv(\"/home/blitt/projects/localNews/data/processed/translated_200_56.tsv\", sep=\"\\t\")\n",
    "\n",
    "#put ground truth values into a list \n",
    "df[\"ground_truth\"] = df['Overall']\n",
    "\n",
    "#get only the columns we need \n",
    "#for when using merged text\n",
    "leanDf = df[[\"ground_truth\",  'text1Merged', 'text2Merged', 'url1_lang', 'url2_lang']].dropna()\n",
    "\n",
    "#rescale data from (0, 4): (0, 1)\n",
    "leanDf[\"ground_truth\"] = 1 - ((leanDf[\"ground_truth\"] - 1) / 3)\n",
    "\n",
    "#reset index so it is contiguous set of numbers \n",
    "leanDf = leanDf.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>text1Merged</th>\n",
       "      <th>text2Merged</th>\n",
       "      <th>url1_lang</th>\n",
       "      <th>url2_lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>Virginia man arrested in fatal DUI crash in We...</td>\n",
       "      <td>Haiti’s leader marks independence day amid sec...</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>Guyana: Three injured after car crashes into u...</td>\n",
       "      <td>Fire kills more than 30 animals at zoo in west...</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>Trump Brings In 2020 At Mar-a-Lago: ‘We’re Goi...</td>\n",
       "      <td>Trump says he does not expect war with Iran, ‘...</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>Zomato Buys Uber's Food Delivery Business in I...</td>\n",
       "      <td>Indian Online Food Delivery Market to Hit $8 B...</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.916667</td>\n",
       "      <td>India approves third moon mission, months afte...</td>\n",
       "      <td>India targets new moon mission in 2020BANGALOR...</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4801</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>The UN announced that more than 2,000 internal...</td>\n",
       "      <td>Description of the risk of death of women at b...</td>\n",
       "      <td>tr</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4802</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>Struggle to survive in La Liga clubs due to Ko...</td>\n",
       "      <td>Fabio Capello: Only Real Madrid will survive i...</td>\n",
       "      <td>tr</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4803</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>The palace was not a cure: 'Giant Clubs drowne...</td>\n",
       "      <td>JET Answer from TFF! '' They are targeting us ...</td>\n",
       "      <td>tr</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4804</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>Ergene Municipality continues its road works w...</td>\n",
       "      <td>Mask was distributed in Ahimehmet and Yeşiltep...</td>\n",
       "      <td>tr</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4805</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>Group commentary members forcibly started... I...</td>\n",
       "      <td>Prosecutor's Office Karşıyaka Judge Sarısu too...</td>\n",
       "      <td>tr</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4806 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ground_truth                                        text1Merged  \\\n",
       "0         0.000000  Virginia man arrested in fatal DUI crash in We...   \n",
       "1         0.111111  Guyana: Three injured after car crashes into u...   \n",
       "2         0.555556  Trump Brings In 2020 At Mar-a-Lago: ‘We’re Goi...   \n",
       "3         0.666667  Zomato Buys Uber's Food Delivery Business in I...   \n",
       "4         0.916667  India approves third moon mission, months afte...   \n",
       "...            ...                                                ...   \n",
       "4801      0.333333  The UN announced that more than 2,000 internal...   \n",
       "4802      1.000000  Struggle to survive in La Liga clubs due to Ko...   \n",
       "4803      0.333333  The palace was not a cure: 'Giant Clubs drowne...   \n",
       "4804      0.333333  Ergene Municipality continues its road works w...   \n",
       "4805      0.666667  Group commentary members forcibly started... I...   \n",
       "\n",
       "                                            text2Merged url1_lang url2_lang  \n",
       "0     Haiti’s leader marks independence day amid sec...        en        en  \n",
       "1     Fire kills more than 30 animals at zoo in west...        en        en  \n",
       "2     Trump says he does not expect war with Iran, ‘...        en        en  \n",
       "3     Indian Online Food Delivery Market to Hit $8 B...        en        en  \n",
       "4     India targets new moon mission in 2020BANGALOR...        en        en  \n",
       "...                                                 ...       ...       ...  \n",
       "4801  Description of the risk of death of women at b...        tr        tr  \n",
       "4802  Fabio Capello: Only Real Madrid will survive i...        tr        tr  \n",
       "4803  JET Answer from TFF! '' They are targeting us ...        tr        tr  \n",
       "4804  Mask was distributed in Ahimehmet and Yeşiltep...        tr        tr  \n",
       "4805  Prosecutor's Office Karşıyaka Judge Sarısu too...        tr        tr  \n",
       "\n",
       "[4806 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leanDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NO LANG CUTOFF \n",
    "#NOTE: do a language cutoff \n",
    "#langList = [\"en\", \"fr\", \"es\"]\n",
    "#leanDf = leanDf[(leanDf[\"url1_lang\"].isin(langList)) & (leanDf[\"url2_lang\"].isin(langList))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(token_embeddings, attention_mask):\n",
    "     #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module): \n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()\n",
    "        self.model = RobertaModel.from_pretrained('roberta-base')\n",
    "        self.l1 = nn.Linear(768, 256).to(device)\n",
    "        self.l2 = nn.Linear(256, 1)\n",
    "        self.GELU = nn.GELU()\n",
    "        self.loss_func = torch.nn.MSELoss(reduction=\"mean\")\n",
    "        \n",
    "    def mean_pooling(self, token_embeddings, attention_mask): \n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask): \n",
    "        \n",
    "        #encode sentence and get mean pooled sentence representation \n",
    "        encoding1 = self.model(input_ids, attention_mask=attention_mask)[0]  #all token embeddings\n",
    "        meanPooled1 = self.mean_pooling(encoding1, attention_mask)\n",
    "       \n",
    "        pred1 = self.l2(self.GELU(self.l1(meanPooled1)))\n",
    "        \n",
    "        encoding2 = self.model(input_ids, attention_mask=attention_mask)[0]  #all token embeddings\n",
    "        meanPooled2 = self.mean_pooling(encoding2, attention_mask)\n",
    "        \n",
    "        pred2 = self.l2(self.GELU(self.l1(meanPooled2)))\n",
    "        \n",
    "        \n",
    "        return [pred1, pred2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, validLoader, loss_func): \n",
    "    model.eval()\n",
    "    lossList = []\n",
    "    predList = []\n",
    "    GT = []\n",
    "\n",
    "    i = True \n",
    "    for batch in validLoader: \n",
    "\n",
    "        # prepare batches and more all to the active device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        label = batch['ground_truth'].to(device).unsqueeze(1)\n",
    "\n",
    "        #send batch info through model \n",
    "        pred1, pred2 = model(input_ids, attention_mask)\n",
    "        #pred1, pred2 = pred1.unsqueeze(0), pred2.unsqueeze(0)\n",
    "        \n",
    "        #get loss relating to label prediction \n",
    "        loss1 = loss_func(label, pred1) * FORWARD_WEIGHT \n",
    "        loss2 = loss_func(label, pred2) * FORWARD_WEIGHT\n",
    "        loss_r = loss_func(pred1, pred2) * RDROP_WEIGHT\n",
    "        loss = (loss1 + loss2 + loss_r)\n",
    "        \n",
    "        #get output metrics \n",
    "        lossList.append(loss1.detach().cpu().item())\n",
    "        predList.append(float(pred1.detach().cpu()))\n",
    "        GT.append(float(label.detach().cpu()))\n",
    "        \n",
    "        del loss1\n",
    "        del loss2\n",
    "        del loss_r\n",
    "        del loss\n",
    "        del pred1\n",
    "        del pred2\n",
    "        del label \n",
    "    #print(vGT)\n",
    "    return [lossList, predList, GT]\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up relevant variables \n",
    "def train(trainDataset, validDataset): \n",
    "    torch.cuda.empty_cache()\n",
    "    #get loaders \n",
    "    trainLoader = torch.utils.data.DataLoader(\n",
    "        trainDataset, batch_size=BATCH_SIZE, shuffle=True\n",
    "    )\n",
    "    validLoader = torch.utils.data.DataLoader(\n",
    "        validDataset, batch_size=1, shuffle=True\n",
    "    )\n",
    "    \n",
    "    trainLen = len(trainDataset)\n",
    "\n",
    "    #load the model \n",
    "    model = Model().to(device)\n",
    "\n",
    "    #TODO: double check on if reduction=\"mean\" is the right move here...\n",
    "    #could cosine similarity also work..? I think that is between the two predicted vectors though.. \n",
    "    loss_func = torch.nn.MSELoss(reduction=\"mean\")\n",
    "\n",
    "    # we would initialize everything first\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "\n",
    "    #set up scheduler\n",
    "    # and setup a warmup for the first ~10% steps\n",
    "    total_steps = int((trainLen*EPOCHS) / BATCH_SIZE)\n",
    "    warmup_steps = int(0.1 * total_steps)\n",
    "    scheduler = get_linear_schedule_with_warmup(optim, num_warmup_steps=warmup_steps, num_training_steps=total_steps - warmup_steps)\n",
    "    \n",
    "    \n",
    "    #now run training loop \n",
    "    lossList = []\n",
    "    validMetrics = []\n",
    "    subLossList = []\n",
    "    # increase from 1 epoch if need be \n",
    "    for epoch in range(EPOCHS):\n",
    "        torch.cuda.empty_cache()\n",
    "        model.train()  # make sure model is in training mode\n",
    "\n",
    "        # initialize the dataloader loop with tqdm (tqdm == progress bar)\n",
    "        loop = tqdm(trainLoader, leave=True)\n",
    "\n",
    "        validMetrics.append(validation(model, validLoader, loss_func))\n",
    "        model.train()\n",
    "\n",
    "        for i, batch in enumerate(loop): \n",
    "            # zero all gradients on each new step\n",
    "            optim.zero_grad()\n",
    "\n",
    "            # prepare batches and more all to the active device\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            label = batch['ground_truth'].to(device).unsqueeze(1)\n",
    "\n",
    "            #send batch info through model \n",
    "            pred1, pred2 = model(input_ids, attention_mask)\n",
    "            #pred1, pred2 = pred1.unsqueeze(0), pred2.unsqueeze(0)\n",
    "            \n",
    "            print(label.size())\n",
    "            print(pred1.size())\n",
    "            print(pred2.size())\n",
    "            #get loss for label prediction, rdrop \n",
    "            loss1 = loss_func(label, pred1) * FORWARD_WEIGHT \n",
    "            loss2 = loss_func(label, pred2) * FORWARD_WEIGHT\n",
    "            loss_r = loss_func(pred1, pred2) * RDROP_WEIGHT\n",
    "            loss = (loss1 + loss2 + loss_r)\n",
    "\n",
    "            # using loss, calculate gradients and then optimize\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            #get mean loss over last 20 batches \n",
    "            if i % 20 == 0: \n",
    "                lossList.append(np.mean(subLossList))\n",
    "                subLossList = []\n",
    "                pass\n",
    "\n",
    "            subLossList.append(float(loss.detach().item()))\n",
    "            \n",
    "\n",
    "            # update learning rate scheduler\n",
    "            scheduler.step()\n",
    "\n",
    "            # update the TDQM progress bar\n",
    "            loop.set_description(f'Epoch {epoch}')\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "            del loss1\n",
    "            del loss2\n",
    "            del loss_r\n",
    "            del loss\n",
    "        print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
    "        print(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "        print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))\n",
    "\n",
    "    validMetrics.append(validation(model, validLoader, loss_func))\n",
    "    return validMetrics \n",
    "    del model\n",
    "    del trainLoader\n",
    "    del validLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=FOLDS, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total df len: 4806\n",
      "English df len: 1738\n",
      "###### 0 ######\n",
      "Train df len: 4458\n",
      "Valid df len: 348\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd63f115f6f6459ab845aa69fdc237e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4458 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc7c2ade3cee4f9ba903e2a954a0ca5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/348 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9086218a2f724f4487b7b9469c9c6d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/892 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/anaconda/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n",
      "torch.Size([5, 1])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-bcaa44dbc066>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mtrainDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'torch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ground_truth\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mvalidMetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidMetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-520ea1c09ea3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(trainDataset, validDataset)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;31m#send batch info through model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mpred1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0;31m#pred1, pred2 = pred1.unsqueeze(0), pred2.unsqueeze(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-aec6d47f26a4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mpred1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGELU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeanPooled1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mencoding2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m#all token embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mmeanPooled2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_pooling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    851\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         )\n\u001b[0;32m--> 853\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    854\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    525\u001b[0m                 )\n\u001b[1;32m    526\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    528\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    455\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         )\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#time how long it takes \n",
    "st = time.time()\n",
    "\n",
    "metrics = []\n",
    "transformers.logging.set_verbosity_error()\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "#JUST FOR TESTING \n",
    "#leanDf = leanDf[:300]\n",
    "\n",
    "#we only want to sample validation data from the pairs that are both english \n",
    "enDf = leanDf[(leanDf[\"url1_lang\"] == \"en\") & (leanDf[\"url2_lang\"] == \"en\")]\n",
    "\n",
    "print(\"Total df len: \" +  str(len(leanDf)))\n",
    "print(\"English df len: \" +  str(len(enDf)))\n",
    "#we create splits based on the position (not the actual index) of rows in enDf\n",
    "#the idea is to get a split of the english dataset to set aside and then \n",
    "#grab everything else in the en + translated dataset to train on \n",
    "for i, (train_index, valid_index) in enumerate(kf.split(enDf)): \n",
    "    \n",
    "    #grab the rows in enDf corresponding to the positions of our split \n",
    "    validDf = enDf.iloc[valid_index]\n",
    "    \n",
    "    #now get the actual indicies that have been selected\n",
    "    #and subtract the indices in trainDf away from those \n",
    "    remainingIndices = list(set(leanDf.index) - set(validDf.index))\n",
    "    trainDf = leanDf.loc[remainingIndices]\n",
    "    print(\"###### \" + str(i).upper() + \" ######\")\n",
    "    print(\"Train df len: \" + str(len(trainDf)))\n",
    "    print(\"Valid df len: \" + str(len(validDf)))\n",
    "    \n",
    "    #get data loaded in properly \n",
    "    trainDataset = Dataset.from_pandas(trainDf)\n",
    "    validDataset = Dataset.from_pandas(validDf)\n",
    "    \n",
    "    \n",
    "    trainDataset = trainDataset.map(lambda x: tokenizer(x[\"text1Merged\"], x[\"text2Merged\"], max_length=512, padding=\"max_length\", truncation=True))\n",
    "    validDataset = validDataset.map(lambda x: tokenizer(x[\"text1Merged\"], x[\"text2Merged\"], max_length=512, padding=\"max_length\", truncation=True))\n",
    "\n",
    "    #only need the input information \n",
    "    trainDataset = trainDataset.remove_columns([\"text1Merged\", \"text2Merged\", \"__index_level_0__\"])\n",
    "    validDataset = validDataset.remove_columns([\"text1Merged\", \"text2Merged\", \"__index_level_0__\"])\n",
    "\n",
    "    # convert dataset features to PyTorch tensors\n",
    "    validDataset.set_format(type='torch', columns=[\"ground_truth\", \"input_ids\", \"attention_mask\"])\n",
    "    trainDataset.set_format(type='torch', columns=[\"ground_truth\", \"input_ids\", \"attention_mask\"])\n",
    "\n",
    "    validMetrics = train(trainDataset, validDataset)\n",
    "    metrics.append(validMetrics)\n",
    "    \n",
    "    del trainDataset\n",
    "    del validDataset\n",
    "    \n",
    "\n",
    "et = time.time()\n",
    "elapsed = et - st\n",
    "print(\"ELAPSED TIME\")\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to an output folder \n",
    "import pickle \n",
    "with open(RESULTS_PATH + \"/outputData.pkl\", \"wb\") as f: \n",
    "    pickle.dump(metrics, f)\n",
    "    \n",
    "with open(RESULTS_PATH + \"/time.pkl\", \"wb\") as f: \n",
    "    pickle.dump(elapsed, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the dimensions should correspond to fold number, epoch number, metric number, and batch number \n",
    "np.array(metrics).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterList = []\n",
    "corrList = []\n",
    "#go through each epoch \n",
    "for epoch in range(EPOCHS): \n",
    "    corrList = []\n",
    "    for fold in range(FOLDS):\n",
    "\n",
    "        df = pd.DataFrame(metrics[fold][epoch]).T\n",
    "        df.columns =  [\"loss\", \"pred\", \"true\"]\n",
    "        corr = np.corrcoef(df[\"pred\"], df[\"true\"])[1,0]\n",
    "        corrList.append(corr)\n",
    "    print(\"Epoch: \" + str(epoch))\n",
    "    print(\"Average Correlation: \" + str(np.mean(corrList)))\n",
    "    \"\"\"\n",
    "    subDf = pd.DataFrame(validArr[i].T)\n",
    "    subDf.columns = [\"loss\", \"pred\", \"true\"]\n",
    "    corr = np.corrcoef(subDf[\"pred\"], subDf[\"true\"])\n",
    "    corrList.append(corr[1, 0])\n",
    "    iterList.append(i)\n",
    "    print(corr)\n",
    "    \"\"\"\n",
    "pass\n",
    "\"\"\"\n",
    "plt.plot(iterList, corrList)\n",
    "plt.xlabel(\"batch num\")\n",
    "plt.ylabel(\"pearson correlation\")\n",
    "plt.title(\"validation eval\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
