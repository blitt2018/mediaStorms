{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News Article Similarity Modelling\n",
    "- Cross encoding \n",
    "- Translated data \n",
    "- Using Title "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch \n",
    "import random\n",
    "from torch import nn\n",
    "from transformers import RobertaTokenizer, PreTrainedTokenizer, DistilBertTokenizer, DistilBertModel, RobertaModel\n",
    "from sentence_transformers import SentenceTransformer, SentencesDataset, InputExample, losses\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from transformers.optimization import get_linear_schedule_with_warmup\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.nn import CosineEmbeddingLoss\n",
    "import transformers\n",
    "import seaborn as sns\n",
    "#Build up to SBERT model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "deviceNum = 1\n",
    "device = torch.device(\"cuda:\" + str(deviceNum) if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAD_ACC = 6\n",
    "EPOCHS = 3\n",
    "FOLDS = 5\n",
    "SEED = 85\n",
    "BATCH_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.memory_allocated: 0.000000GB\n",
      "torch.cuda.memory_reserved: 0.000000GB\n",
      "torch.cuda.memory_free: 0.000000GB\n",
      "torch.cuda.max_memory_reserved: 0.000000GB\n"
     ]
    }
   ],
   "source": [
    "def check_mem():\n",
    "    torch.cuda.empty_cache()\n",
    "    a = torch.cuda.memory_allocated(deviceNum)/1024/1024/1024\n",
    "    r = torch.cuda.memory_reserved(deviceNum)/1024/1024/1024\n",
    "    print(\"torch.cuda.memory_allocated: %fGB\"%a)\n",
    "    print(\"torch.cuda.memory_reserved: %fGB\"%r)\n",
    "    print(\"torch.cuda.memory_free: %fGB\"%(r-a))\n",
    "    print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(deviceNum)/1024/1024/1024))\n",
    "check_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set seeds \n",
    "torch.manual_seed(85)\n",
    "random.seed(85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/blitt/projects/localNews/data/processed/translated_200_56.tsv\", sep=\"\\t\")\n",
    "#df = df.loc[(df[\"url1_lang\"] == \"en\") & (df[\"url2_lang\"] == \"en\")]\n",
    "\n",
    "groundTruths = [\"Geography\", \"Entities\",\"Time\", \"Narrative\", \"Overall\"]\n",
    "features = ['text1Merged', 'text2Merged','url1_lang', 'url2_lang']\n",
    "toSelect = groundTruths + features \n",
    " \n",
    "#get only the columns we need \n",
    "#TODO: do we need \"pair_id\"? \n",
    "leanDf = df[toSelect].dropna()\n",
    "\n",
    "#rescale data from (0, 4): (0, 1)\n",
    "for colName in groundTruths: \n",
    "    leanDf[colName] = 1 - ((leanDf[colName] - 1) / 3)\n",
    "\n",
    "#reset index so it is contiguous set of numbers \n",
    "leanDf = leanDf.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module): \n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()\n",
    "        self.model = RobertaModel.from_pretrained('roberta-base')\n",
    "        self.l1 = nn.Linear(768, 5).to(device)\n",
    "        self.loss_func = torch.nn.MSELoss(reduction=\"mean\")\n",
    "        \n",
    "    def mean_pooling(self, token_embeddings, attention_mask): \n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask): \n",
    "        \n",
    "        #encode sentence and get mean pooled sentence representation \n",
    "        encoding = self.model(input_ids, attention_mask=attention_mask)[0]  #all token embeddings\n",
    "        meanPooled = self.mean_pooling(encoding, attention_mask)\n",
    "       \n",
    "        pred = self.l1(meanPooled)\n",
    "        \n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get the loss across multiple different objectives. \n",
    "Since overall is most important it gets more weight. \n",
    "\"\"\"\n",
    "def getWeightedLoss(predTens, gtTens):\n",
    "    loss_func = torch.nn.MSELoss(reduction=\"mean\")\n",
    "    #try getting rid of Tone and Style \n",
    "    LOSS_WEIGHTS = [.1, .1, .1, .1, .6]\n",
    "    loss = 0.0\n",
    "    for i in range(len(LOSS_WEIGHTS)): \n",
    "        \n",
    "        #get ground truth value associated with this column name \n",
    "        currGT = gtTens[:, :, i]\n",
    "        \n",
    "        #TODO: figure out how to index properly here \n",
    "        pred = predTens[:, :, i]\n",
    "        \n",
    "        #get loss \n",
    "        loss += (loss_func(pred, currGT) * LOSS_WEIGHTS[i])\n",
    "    return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, validLoader, loss_func): \n",
    "    model.eval()\n",
    "    lossList = []\n",
    "    predList = []\n",
    "    GT = []\n",
    "    \n",
    "    i = True \n",
    "    for batch in validLoader: \n",
    "\n",
    "        # prepare batches and more all to the active device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        #label = batch['ground_truth'].to(device).unsqueeze(1)\n",
    "\n",
    "        #send batch info through model \n",
    "        pred = model(input_ids, attention_mask).unsqueeze(0)\n",
    "        \n",
    "        #get ground truths \n",
    "        gts = torch.stack([batch[colName] for colName in groundTruths], 0).to(device).T.unsqueeze(0)\n",
    "        \n",
    "        #get weighted loss relating to label prediction \n",
    "        loss = getWeightedLoss(gts, pred)\n",
    "    \n",
    "        #get output metrics \n",
    "        lossList.append(loss.detach().cpu().item())\n",
    "        predList.append([float(item) for item in list(pred.detach().cpu().squeeze())])\n",
    "        GT.append([float(item) for item in list(gts.detach().cpu().squeeze())])\n",
    "        \n",
    "        del pred\n",
    "        del gts\n",
    "        del loss\n",
    "    #print(vGT)\n",
    "    return [lossList, predList, GT]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up relevant variables \n",
    "def train(trainDataset, validDataset): \n",
    "    torch.cuda.empty_cache()\n",
    "    #get loaders \n",
    "    trainLoader = torch.utils.data.DataLoader(\n",
    "        trainDataset, batch_size=BATCH_SIZE, shuffle=True\n",
    "    )\n",
    "    validLoader = torch.utils.data.DataLoader(\n",
    "        validDataset, batch_size=1, shuffle=True\n",
    "    )\n",
    "    \n",
    "    trainLen = len(trainDataset)\n",
    "\n",
    "    #load the model \n",
    "    model = Model().to(device)\n",
    "\n",
    "    #TODO: double check on if reduction=\"mean\" is the right move here...\n",
    "    #could cosine similarity also work..? I think that is between the two predicted vectors though.. \n",
    "    loss_func = torch.nn.MSELoss(reduction=\"mean\")\n",
    "\n",
    "    # we would initialize everything first\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "\n",
    "    #set up scheduler\n",
    "    # and setup a warmup for the first ~10% steps\n",
    "    total_steps = int((trainLen*EPOCHS) / BATCH_SIZE)\n",
    "    warmup_steps = int(0.1 * total_steps)\n",
    "    scheduler = get_linear_schedule_with_warmup(optim, num_warmup_steps=warmup_steps, num_training_steps=total_steps - warmup_steps)\n",
    "    \n",
    "    \n",
    "    #now run training loop \n",
    "    lossList = []\n",
    "    validMetrics = []\n",
    "    subLossList = []\n",
    "    \n",
    "    # increase from 1 epoch if need be \n",
    "    for epoch in range(EPOCHS):\n",
    "        torch.cuda.empty_cache()\n",
    "        model.train()  # make sure model is in training mode\n",
    "\n",
    "        # initialize the dataloader loop with tqdm (tqdm == progress bar)\n",
    "        loop = tqdm(trainLoader, leave=True)\n",
    "\n",
    "        validMetrics.append(validation(model, validLoader, loss_func))\n",
    "        model.train()\n",
    "\n",
    "        for i, batch in enumerate(loop): \n",
    "            # zero all gradients on each new step\n",
    "            optim.zero_grad()\n",
    "\n",
    "            # prepare batches and more all to the active device\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "           \n",
    "            #send batch info through model \n",
    "            pred = model(input_ids, attention_mask).unsqueeze(0)\n",
    "\n",
    "            #get gts \n",
    "            gts = torch.stack([batch[colName] for colName in groundTruths], 0).T.to(device).unsqueeze(0)\n",
    "        \n",
    "            #get loss relating to label prediction \n",
    "            loss = getWeightedLoss(gts, pred) / GRAD_ACC\n",
    "            \n",
    "            # using loss, calculate gradients and then optimize\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            #get mean loss over last 20 batches \n",
    "            if i % 20 == 0: \n",
    "                lossList.append(np.mean(subLossList))\n",
    "                subLossList = []\n",
    "                pass\n",
    "\n",
    "            subLossList.append(float(loss.detach().item()))\n",
    "        \n",
    "            # update learning rate scheduler\n",
    "            scheduler.step()\n",
    "\n",
    "            # update the TDQM progress bar\n",
    "            loop.set_description(f'Epoch {epoch}')\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "            del loss \n",
    "        print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
    "        print(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "        print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))\n",
    "\n",
    "    validMetrics.append(validation(model, validLoader, loss_func))\n",
    "    del model\n",
    "    del trainLoader\n",
    "    del validLoader\n",
    "    return validMetrics \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=FOLDS, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total df len: 4806\n",
      "English df len: 1738\n",
      "###### 0 ######\n",
      "Train df len: 4458\n",
      "Valid df len: 348\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27c4348cb9f8447482358b91a88d8a16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4458 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e322cdcb5ccb4adda2c36ef4a17360ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/348 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c2d592515240ce86badb63ae2b6184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/892 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/anaconda/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.memory_allocated: 0.000000GB\n",
      "torch.cuda.memory_reserved: 0.000000GB\n",
      "torch.cuda.max_memory_reserved: 0.000000GB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8a704b2f6214ff585fe7827af8450bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/892 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.memory_allocated: 0.000000GB\n",
      "torch.cuda.memory_reserved: 0.000000GB\n",
      "torch.cuda.max_memory_reserved: 0.000000GB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "782cc36a729a493fb68931e7f9f5d013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/892 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.memory_allocated: 0.000000GB\n",
      "torch.cuda.memory_reserved: 0.000000GB\n",
      "torch.cuda.max_memory_reserved: 0.000000GB\n",
      "1\n",
      "Wed Jan 18 11:52:59 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A5000    Off  | 00000000:04:00.0 Off |                  Off |\n",
      "| 30%   24C    P8     8W / 230W |  12365MiB / 24256MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 70%   81C    P2    84W / 250W |   6605MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  Off  | 00000000:08:00.0 Off |                  N/A |\n",
      "| 70%   83C    P2   251W / 250W |  10193MiB / 11178MiB |     96%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce ...  Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "| 28%   30C    P8     8W / 250W |   6769MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA GeForce ...  Off  | 00000000:84:00.0 Off |                  N/A |\n",
      "| 29%   25C    P8     9W / 250W |      2MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA GeForce ...  Off  | 00000000:85:00.0 Off |                  N/A |\n",
      "| 29%   21C    P8     7W / 250W |   2201MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA GeForce ...  Off  | 00000000:88:00.0 Off |                  N/A |\n",
      "| 29%   20C    P8     8W / 250W |   8137MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      7641      C   /opt/anaconda/bin/python         8543MiB |\n",
      "|    0   N/A  N/A     11034      C   /opt/anaconda/bin/python          199MiB |\n",
      "|    0   N/A  N/A     11148      C   /opt/anaconda/bin/python          199MiB |\n",
      "|    0   N/A  N/A     12551      C   /opt/anaconda/bin/python          345MiB |\n",
      "|    0   N/A  N/A     27076      C   /opt/anaconda/bin/python         3077MiB |\n",
      "|    1   N/A  N/A     11034      C   /opt/anaconda/bin/python         6603MiB |\n",
      "|    2   N/A  N/A     11148      C   /opt/anaconda/bin/python        10191MiB |\n",
      "|    3   N/A  N/A     10046      C   /opt/anaconda/bin/python         6767MiB |\n",
      "|    5   N/A  N/A      2681      C   /opt/anaconda/bin/python         2199MiB |\n",
      "|    6   N/A  N/A      6494      C   /opt/anaconda/bin/python         8135MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "###### 1 ######\n",
      "Train df len: 4458\n",
      "Valid df len: 348\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c7514a6114c424b8497e461c3cf7885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4458 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e72d465939a94eaf8f8adb4620b6a371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/348 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb4c86af95e64bb48cee87f96d5c0ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/892 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.memory_allocated: 0.000000GB\n",
      "torch.cuda.memory_reserved: 0.000000GB\n",
      "torch.cuda.max_memory_reserved: 0.000000GB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "981755cd3c874349910fe991cc39a6f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/892 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.memory_allocated: 0.000000GB\n",
      "torch.cuda.memory_reserved: 0.000000GB\n",
      "torch.cuda.max_memory_reserved: 0.000000GB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16819578007b4b3fb61795e633832d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/892 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.memory_allocated: 0.000000GB\n",
      "torch.cuda.memory_reserved: 0.000000GB\n",
      "torch.cuda.max_memory_reserved: 0.000000GB\n",
      "2\n",
      "Wed Jan 18 12:06:53 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A5000    Off  | 00000000:04:00.0 Off |                  Off |\n",
      "| 30%   23C    P8     8W / 230W |  12365MiB / 24256MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 70%   81C    P2    82W / 250W |   6605MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  Off  | 00000000:08:00.0 Off |                  N/A |\n",
      "| 59%   78C    P2   242W / 250W |   9599MiB / 11178MiB |     94%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce ...  Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "| 28%   29C    P8     8W / 250W |   6769MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA GeForce ...  Off  | 00000000:84:00.0 Off |                  N/A |\n",
      "| 29%   24C    P8     8W / 250W |      2MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA GeForce ...  Off  | 00000000:85:00.0 Off |                  N/A |\n",
      "| 29%   20C    P8     7W / 250W |   2201MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA GeForce ...  Off  | 00000000:88:00.0 Off |                  N/A |\n",
      "| 29%   19C    P8     8W / 250W |   8137MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      7641      C   /opt/anaconda/bin/python         8543MiB |\n",
      "|    0   N/A  N/A     11034      C   /opt/anaconda/bin/python          199MiB |\n",
      "|    0   N/A  N/A     11148      C   /opt/anaconda/bin/python          199MiB |\n",
      "|    0   N/A  N/A     12551      C   /opt/anaconda/bin/python          345MiB |\n",
      "|    0   N/A  N/A     27076      C   /opt/anaconda/bin/python         3077MiB |\n",
      "|    1   N/A  N/A     11034      C   /opt/anaconda/bin/python         6603MiB |\n",
      "|    2   N/A  N/A     11148      C   /opt/anaconda/bin/python         9597MiB |\n",
      "|    3   N/A  N/A     10046      C   /opt/anaconda/bin/python         6767MiB |\n",
      "|    5   N/A  N/A      2681      C   /opt/anaconda/bin/python         2199MiB |\n",
      "|    6   N/A  N/A      6494      C   /opt/anaconda/bin/python         8135MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "###### 2 ######\n",
      "Train df len: 4458\n",
      "Valid df len: 348\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c7286cc512441aeae151aa5b0a8a0b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4458 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7dbd57ab7464c379b14b8b0d7b55ab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/348 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90822b667d314beaa0214613a699cdae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/892 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.memory_allocated: 0.000000GB\n",
      "torch.cuda.memory_reserved: 0.000000GB\n",
      "torch.cuda.max_memory_reserved: 0.000000GB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adf218afe71e48029970376ad131263f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/892 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.memory_allocated: 0.000000GB\n",
      "torch.cuda.memory_reserved: 0.000000GB\n",
      "torch.cuda.max_memory_reserved: 0.000000GB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7528464ac3704f4aa780ac0a93af6d1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/892 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.memory_allocated: 0.000000GB\n",
      "torch.cuda.memory_reserved: 0.000000GB\n",
      "torch.cuda.max_memory_reserved: 0.000000GB\n",
      "3\n",
      "Wed Jan 18 12:20:48 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A5000    Off  | 00000000:04:00.0 Off |                  Off |\n",
      "| 30%   30C    P8    16W / 230W |  12497MiB / 24256MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 69%   81C    P2    84W / 250W |   6605MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  Off  | 00000000:08:00.0 Off |                  N/A |\n",
      "| 70%   83C    P2   253W / 250W |  10193MiB / 11178MiB |     93%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce ...  Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "| 28%   29C    P8     8W / 250W |   6769MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA GeForce ...  Off  | 00000000:84:00.0 Off |                  N/A |\n",
      "| 29%   24C    P8     8W / 250W |      2MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA GeForce ...  Off  | 00000000:85:00.0 Off |                  N/A |\n",
      "| 29%   20C    P8     7W / 250W |   2201MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA GeForce ...  Off  | 00000000:88:00.0 Off |                  N/A |\n",
      "| 29%   19C    P8     7W / 250W |   8137MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      7641      C   /opt/anaconda/bin/python         8675MiB |\n",
      "|    0   N/A  N/A     11034      C   /opt/anaconda/bin/python          199MiB |\n",
      "|    0   N/A  N/A     11148      C   /opt/anaconda/bin/python          199MiB |\n",
      "|    0   N/A  N/A     12551      C   /opt/anaconda/bin/python          345MiB |\n",
      "|    0   N/A  N/A     27076      C   /opt/anaconda/bin/python         3077MiB |\n",
      "|    1   N/A  N/A     11034      C   /opt/anaconda/bin/python         6603MiB |\n",
      "|    2   N/A  N/A     11148      C   /opt/anaconda/bin/python        10191MiB |\n",
      "|    3   N/A  N/A     10046      C   /opt/anaconda/bin/python         6767MiB |\n",
      "|    5   N/A  N/A      2681      C   /opt/anaconda/bin/python         2199MiB |\n",
      "|    6   N/A  N/A      6494      C   /opt/anaconda/bin/python         8135MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "###### 3 ######\n",
      "Train df len: 4459\n",
      "Valid df len: 347\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4faf7aeae69b4229b64063698f314653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4459 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b28a616ba2e4a5e9bc7774c9c718d23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/347 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f818c00845c74730b21316c7c754790e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/892 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.memory_allocated: 0.000000GB\n",
      "torch.cuda.memory_reserved: 0.000000GB\n",
      "torch.cuda.max_memory_reserved: 0.000000GB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4391a73faf0040708a72296d83071950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/892 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.memory_allocated: 0.000000GB\n",
      "torch.cuda.memory_reserved: 0.000000GB\n",
      "torch.cuda.max_memory_reserved: 0.000000GB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50accea75a914c889c3b2fbd9911eac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/892 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.memory_allocated: 0.000000GB\n",
      "torch.cuda.memory_reserved: 0.000000GB\n",
      "torch.cuda.max_memory_reserved: 0.000000GB\n",
      "4\n",
      "Wed Jan 18 12:34:43 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A5000    Off  | 00000000:04:00.0 Off |                  Off |\n",
      "| 37%   67C    P2   168W / 230W |  12507MiB / 24256MiB |     36%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 74%   81C    P2    84W / 250W |   6605MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  Off  | 00000000:08:00.0 Off |                  N/A |\n",
      "| 67%   82C    P2   221W / 250W |   9599MiB / 11178MiB |     99%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce ...  Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "| 29%   29C    P8     8W / 250W |   6769MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA GeForce ...  Off  | 00000000:84:00.0 Off |                  N/A |\n",
      "| 29%   24C    P8     8W / 250W |      2MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA GeForce ...  Off  | 00000000:85:00.0 Off |                  N/A |\n",
      "| 29%   20C    P8     7W / 250W |   2201MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA GeForce ...  Off  | 00000000:88:00.0 Off |                  N/A |\n",
      "| 29%   19C    P8     8W / 250W |   8137MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      7641      C   /opt/anaconda/bin/python         8685MiB |\n",
      "|    0   N/A  N/A     11034      C   /opt/anaconda/bin/python          199MiB |\n",
      "|    0   N/A  N/A     11148      C   /opt/anaconda/bin/python          199MiB |\n",
      "|    0   N/A  N/A     12551      C   /opt/anaconda/bin/python          345MiB |\n",
      "|    0   N/A  N/A     27076      C   /opt/anaconda/bin/python         3077MiB |\n",
      "|    1   N/A  N/A     11034      C   /opt/anaconda/bin/python         6603MiB |\n",
      "|    2   N/A  N/A     11148      C   /opt/anaconda/bin/python         9597MiB |\n",
      "|    3   N/A  N/A     10046      C   /opt/anaconda/bin/python         6767MiB |\n",
      "|    5   N/A  N/A      2681      C   /opt/anaconda/bin/python         2199MiB |\n",
      "|    6   N/A  N/A      6494      C   /opt/anaconda/bin/python         8135MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "###### 4 ######\n",
      "Train df len: 4459\n",
      "Valid df len: 347\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "244c5d97836d424f8176d62890a82d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4459 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14e3b2bc690b48e2a87e0ff1d1aca798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/347 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f31f5b9874c42d6984309213bfbdf21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/892 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.memory_allocated: 0.000000GB\n",
      "torch.cuda.memory_reserved: 0.000000GB\n",
      "torch.cuda.max_memory_reserved: 0.000000GB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb06727e60f45e8a02a3fb59a8e1f7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/892 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.memory_allocated: 0.000000GB\n",
      "torch.cuda.memory_reserved: 0.000000GB\n",
      "torch.cuda.max_memory_reserved: 0.000000GB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf96e8ada2c4690a81b6e50d01a23ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/892 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.memory_allocated: 0.000000GB\n",
      "torch.cuda.memory_reserved: 0.000000GB\n",
      "torch.cuda.max_memory_reserved: 0.000000GB\n",
      "5\n",
      "Wed Jan 18 12:48:28 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A5000    Off  | 00000000:04:00.0 Off |                  Off |\n",
      "| 38%   62C    P2   132W / 230W |  12507MiB / 24256MiB |     40%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 73%   81C    P2    84W / 250W |   6605MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  Off  | 00000000:08:00.0 Off |                  N/A |\n",
      "| 70%   82C    P2   248W / 250W |  10193MiB / 11178MiB |     99%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce ...  Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "| 28%   29C    P8     8W / 250W |      2MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA GeForce ...  Off  | 00000000:84:00.0 Off |                  N/A |\n",
      "| 29%   24C    P8     8W / 250W |      2MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA GeForce ...  Off  | 00000000:85:00.0 Off |                  N/A |\n",
      "| 29%   20C    P8     7W / 250W |   2201MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA GeForce ...  Off  | 00000000:88:00.0 Off |                  N/A |\n",
      "| 29%   19C    P8     8W / 250W |   8137MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      7641      C   /opt/anaconda/bin/python         8685MiB |\n",
      "|    0   N/A  N/A     11034      C   /opt/anaconda/bin/python          199MiB |\n",
      "|    0   N/A  N/A     11148      C   /opt/anaconda/bin/python          199MiB |\n",
      "|    0   N/A  N/A     12551      C   /opt/anaconda/bin/python          345MiB |\n",
      "|    0   N/A  N/A     27076      C   /opt/anaconda/bin/python         3077MiB |\n",
      "|    1   N/A  N/A     11034      C   /opt/anaconda/bin/python         6603MiB |\n",
      "|    2   N/A  N/A     11148      C   /opt/anaconda/bin/python        10191MiB |\n",
      "|    5   N/A  N/A      2681      C   /opt/anaconda/bin/python         2199MiB |\n",
      "|    6   N/A  N/A      6494      C   /opt/anaconda/bin/python         8135MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "metrics = []\n",
    "transformers.logging.set_verbosity_error()\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "#we only want to sample validation data from the pairs that are both english \n",
    "enDf = leanDf[(leanDf[\"url1_lang\"] == \"en\") & (leanDf[\"url2_lang\"] == \"en\")]\n",
    "\n",
    "print(\"Total df len: \" +  str(len(leanDf)))\n",
    "print(\"English df len: \" +  str(len(enDf)))\n",
    "#we create splits based on the position (not the actual index) of rows in enDf\n",
    "#the idea is to get a split of the english dataset to set aside and then \n",
    "#grab everything else in the en + translated dataset to train on \n",
    "for i, (train_index, valid_index) in enumerate(kf.split(enDf)): \n",
    "    \n",
    "    #grab the rows in enDf corresponding to the positions of our split \n",
    "    validDf = enDf.iloc[valid_index]\n",
    "    \n",
    "    #now get the actual indicies that have been selected\n",
    "    #and subtract the indices in trainDf away from those \n",
    "    remainingIndices = list(set(leanDf.index) - set(validDf.index))\n",
    "    trainDf = leanDf.loc[remainingIndices]\n",
    "    print(\"###### \" + str(i).upper() + \" ######\")\n",
    "    print(\"Train df len: \" + str(len(trainDf)))\n",
    "    print(\"Valid df len: \" + str(len(validDf)))\n",
    "    \n",
    "    #get data loaded in properly \n",
    "    trainDataset = Dataset.from_pandas(trainDf)\n",
    "    validDataset = Dataset.from_pandas(validDf)\n",
    "    \n",
    "    #NOTE: here we use the merged text\n",
    "    trainDataset = trainDataset.map(lambda x: tokenizer(x[\"text1Merged\"], x[\"text2Merged\"], max_length=512, padding=\"max_length\", truncation=True))\n",
    "    validDataset = validDataset.map(lambda x: tokenizer(x[\"text1Merged\"], x[\"text2Merged\"], max_length=512, padding=\"max_length\", truncation=True))\n",
    "    \n",
    "\n",
    "    #only need the input information \n",
    "    trainDataset = trainDataset.remove_columns([\"text1Merged\", \"text2Merged\", \"__index_level_0__\"])\n",
    "    validDataset = validDataset.remove_columns([\"text1Merged\", \"text2Merged\", \"__index_level_0__\"])\n",
    "    \n",
    "    # convert dataset features to PyTorch tensors\n",
    "    formatColumns = groundTruths + [\"input_ids\", \"attention_mask\"]\n",
    "    validDataset.set_format(type='torch', columns=formatColumns)\n",
    "    trainDataset.set_format(type='torch', columns=formatColumns)\n",
    "\n",
    "    validMetrics = train(trainDataset, validDataset)\n",
    "    metrics.append(validMetrics)\n",
    "    print(len(metrics))\n",
    "    del trainDataset\n",
    "    del validDataset\n",
    "    !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving this cell, undo if we need old code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochList = []\n",
    "foldList = []\n",
    "corrList = []\n",
    "for epoch in range(EPOCHS): \n",
    "    for fold in range(FOLDS): \n",
    "        df = pd.DataFrame(metrics[fold][epoch]).T\n",
    "        df.columns = [\"loss\", \"pred\", \"true\"]\n",
    "        #corr = np.corrcoef(df[\"pred\"], df[\"true\"])\n",
    "\n",
    "        predCols = [\"pred\" + item for item in groundTruths]\n",
    "        gtCols = [\"gt\" + item for item in groundTruths]\n",
    "\n",
    "        df[predCols] = pd.DataFrame(df[\"pred\"].tolist(), index=df.index)\n",
    "        df[gtCols] = pd.DataFrame(df[\"true\"].tolist(), index=df.index)\n",
    "\n",
    "        corrScores = []\n",
    "        for colName in groundTruths: \n",
    "            corr = np.corrcoef(df[\"pred\" + colName], df[\"gt\" + colName])[1, 0]\n",
    "            corrScores.append(corr)\n",
    "        epochList.append(epoch)\n",
    "        foldList.append(fold)\n",
    "        corrList.append(corrScores)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.42599859833717346,\n",
       " 0.19772666692733765,\n",
       " 0.7713460326194763,\n",
       " 0.14386795461177826,\n",
       " 0.17335015535354614]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"pred\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"epoch\":epochList, \"fold\":foldList, \"corrList\":corrList})\n",
    "df[gtCols] = pd.DataFrame(df[\"corrList\"].tolist(), index=df.index)\n",
    "df = df.drop(columns=[\"corrList\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>gtGeography</th>\n",
       "      <th>gtEntities</th>\n",
       "      <th>gtTime</th>\n",
       "      <th>gtNarrative</th>\n",
       "      <th>gtOverall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.009619</td>\n",
       "      <td>-0.080576</td>\n",
       "      <td>0.108484</td>\n",
       "      <td>-0.025543</td>\n",
       "      <td>-0.019963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.679692</td>\n",
       "      <td>0.829344</td>\n",
       "      <td>0.356246</td>\n",
       "      <td>0.814812</td>\n",
       "      <td>0.852245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.738554</td>\n",
       "      <td>0.843574</td>\n",
       "      <td>0.373039</td>\n",
       "      <td>0.834543</td>\n",
       "      <td>0.874976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fold  gtGeography  gtEntities    gtTime  gtNarrative  gtOverall\n",
       "epoch                                                                 \n",
       "0         2    -0.009619   -0.080576  0.108484    -0.025543  -0.019963\n",
       "1         2     0.679692    0.829344  0.356246     0.814812   0.852245\n",
       "2         2     0.738554    0.843574  0.373039     0.834543   0.874976"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(by=\"epoch\").agg(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>fold</th>\n",
       "      <th>gtGeography</th>\n",
       "      <th>gtEntities</th>\n",
       "      <th>gtTime</th>\n",
       "      <th>gtNarrative</th>\n",
       "      <th>gtOverall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.048094</td>\n",
       "      <td>-0.023136</td>\n",
       "      <td>0.007887</td>\n",
       "      <td>0.026791</td>\n",
       "      <td>-0.175735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.212379</td>\n",
       "      <td>-0.045275</td>\n",
       "      <td>0.177753</td>\n",
       "      <td>-0.125399</td>\n",
       "      <td>-0.008635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.142628</td>\n",
       "      <td>-0.019238</td>\n",
       "      <td>0.057628</td>\n",
       "      <td>-0.035693</td>\n",
       "      <td>0.019296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.006282</td>\n",
       "      <td>-0.170403</td>\n",
       "      <td>0.106212</td>\n",
       "      <td>0.105626</td>\n",
       "      <td>0.006546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.032720</td>\n",
       "      <td>-0.144826</td>\n",
       "      <td>0.192941</td>\n",
       "      <td>-0.099038</td>\n",
       "      <td>0.058713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.721590</td>\n",
       "      <td>0.872805</td>\n",
       "      <td>0.378181</td>\n",
       "      <td>0.841913</td>\n",
       "      <td>0.857899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.632380</td>\n",
       "      <td>0.822974</td>\n",
       "      <td>0.336394</td>\n",
       "      <td>0.814075</td>\n",
       "      <td>0.853672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.713599</td>\n",
       "      <td>0.823634</td>\n",
       "      <td>0.353132</td>\n",
       "      <td>0.821183</td>\n",
       "      <td>0.852131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.686716</td>\n",
       "      <td>0.783451</td>\n",
       "      <td>0.317251</td>\n",
       "      <td>0.775192</td>\n",
       "      <td>0.829074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.644175</td>\n",
       "      <td>0.843857</td>\n",
       "      <td>0.396271</td>\n",
       "      <td>0.821697</td>\n",
       "      <td>0.868447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.765045</td>\n",
       "      <td>0.886444</td>\n",
       "      <td>0.409453</td>\n",
       "      <td>0.856728</td>\n",
       "      <td>0.880667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727627</td>\n",
       "      <td>0.854113</td>\n",
       "      <td>0.370216</td>\n",
       "      <td>0.851579</td>\n",
       "      <td>0.893076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.766801</td>\n",
       "      <td>0.819570</td>\n",
       "      <td>0.369025</td>\n",
       "      <td>0.845317</td>\n",
       "      <td>0.878496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.724581</td>\n",
       "      <td>0.802309</td>\n",
       "      <td>0.324643</td>\n",
       "      <td>0.785499</td>\n",
       "      <td>0.837895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.708716</td>\n",
       "      <td>0.855433</td>\n",
       "      <td>0.391859</td>\n",
       "      <td>0.833593</td>\n",
       "      <td>0.884744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  fold  gtGeography  gtEntities    gtTime  gtNarrative  gtOverall\n",
       "0       0     0     0.048094   -0.023136  0.007887     0.026791  -0.175735\n",
       "1       0     1    -0.212379   -0.045275  0.177753    -0.125399  -0.008635\n",
       "2       0     2     0.142628   -0.019238  0.057628    -0.035693   0.019296\n",
       "3       0     3     0.006282   -0.170403  0.106212     0.105626   0.006546\n",
       "4       0     4    -0.032720   -0.144826  0.192941    -0.099038   0.058713\n",
       "5       1     0     0.721590    0.872805  0.378181     0.841913   0.857899\n",
       "6       1     1     0.632380    0.822974  0.336394     0.814075   0.853672\n",
       "7       1     2     0.713599    0.823634  0.353132     0.821183   0.852131\n",
       "8       1     3     0.686716    0.783451  0.317251     0.775192   0.829074\n",
       "9       1     4     0.644175    0.843857  0.396271     0.821697   0.868447\n",
       "10      2     0     0.765045    0.886444  0.409453     0.856728   0.880667\n",
       "11      2     1     0.727627    0.854113  0.370216     0.851579   0.893076\n",
       "12      2     2     0.766801    0.819570  0.369025     0.845317   0.878496\n",
       "13      2     3     0.724581    0.802309  0.324643     0.785499   0.837895\n",
       "14      2     4     0.708716    0.855433  0.391859     0.833593   0.884744"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
