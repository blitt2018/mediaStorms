{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch \n",
    "from transformers import DistilBertModel\n",
    "from transformers import DistilBertTokenizer\n",
    "from transformers import PreTrainedTokenizer\n",
    "from sentence_transformers import SentenceTransformer, SentencesDataset, InputExample, losses\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from transformers.optimization import get_linear_schedule_with_warmup\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.nn import CosineEmbeddingLoss\n",
    "import sklearn\n",
    "import spacy\n",
    "from torch import nn\n",
    "#Build up to SBERT model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.memory_allocated: 0.000000GB\n",
      "torch.cuda.memory_reserved: 0.000000GB\n",
      "torch.cuda.memory_free: 0.000000GB\n",
      "torch.cuda.max_memory_reserved: 0.000000GB\n"
     ]
    }
   ],
   "source": [
    "deviceNum = 6\n",
    "\n",
    "device = torch.device(\"cuda:\" + str(deviceNum) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def check_mem():\n",
    "    torch.cuda.empty_cache()\n",
    "    a = torch.cuda.memory_allocated(deviceNum)/1024/1024/1024\n",
    "    r = torch.cuda.memory_reserved(deviceNum)/1024/1024/1024\n",
    "    print(\"torch.cuda.memory_allocated: %fGB\"%a)\n",
    "    print(\"torch.cuda.memory_reserved: %fGB\"%r)\n",
    "    print(\"torch.cuda.memory_free: %fGB\"%(r-a))\n",
    "    print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(deviceNum)/1024/1024/1024))\n",
    "check_mem()\n",
    "\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "df = pd.read_csv(\"/shared/3/projects/benlitterer/localNews/NetworkMVP/enTrainData.csv\", sep=\"\\t\")\n",
    "df = df.loc[(df[\"url1_lang\"] == \"en\") & (df[\"url2_lang\"] == \"en\")]\n",
    "\n",
    "#put ground truth values into a list \n",
    "df[\"ground_truth\"] = df['Overall']\n",
    "\n",
    "#get only the columns we need \n",
    "#TODO: do we need \"pair_id\"? \n",
    "leanDf = df[[\"ground_truth\",  'text1', 'text2']].dropna()\n",
    "\n",
    "#rescale data from (0, 4): (0, 1)\n",
    "leanDf[\"ground_truth\"] = 1 - ((leanDf[\"ground_truth\"] - 1) / 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.000000\n",
       "1       0.111111\n",
       "2       0.555556\n",
       "3       0.666667\n",
       "4       0.916667\n",
       "          ...   \n",
       "2871    0.333333\n",
       "2872    0.000000\n",
       "2873    1.000000\n",
       "2874    1.000000\n",
       "2875    1.000000\n",
       "Name: ground_truth, Length: 1676, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leanDf[\"ground_truth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSentListDataset(Dataset): \n",
    "    def __init__(self, inDf): \n",
    "        self.inDf = inDf \n",
    "        \n",
    "    def __len__(self): \n",
    "        return len(self.inDf)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return list(self.inDf.iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f2f85b2ff534eb08c624e5ecd8f5b74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "992073cc2a6644c695dc7922526a7808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#nlp = spacy.load(\"en_core_web_sm\", disable=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\", \"ner\"])\n",
    "#nlp.enable_pipe(\"senter\")\n",
    "nlp = spacy.blank(\"en\")\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "def extractSents(inList): \n",
    "    separator = nlp.pipe(inList, n_process=8)\n",
    "    textList = []\n",
    "    for text in tqdm(separator): \n",
    "        sentList = [str(sent) for sent in text.sents if len(sent) > 3]\n",
    "        textList.append(sentList)\n",
    "    return textList\n",
    "\n",
    "#split data \n",
    "trainDf, validDf = sklearn.model_selection.train_test_split(leanDf, train_size=.9, test_size=.1)\n",
    "trainDf = trainDf.reset_index(drop=True)\n",
    "validDf = validDf.reset_index(drop=True)\n",
    "\n",
    "trainDf[\"text1\"] = extractSents(trainDf[\"text1\"])\n",
    "trainDf[\"text2\"] = extractSents(trainDf[\"text2\"])\n",
    "validDf[\"text1\"] = extractSents(validDf[\"text1\"])\n",
    "validDf[\"text2\"] = extractSents(validDf[\"text2\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf[\"text1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentCutoff = 50\n",
    " \n",
    "trainDf[\"text1\"] = trainDf[\"text1\"].apply(lambda x: x[:sentCutoff])\n",
    "trainDf[\"text2\"] = trainDf[\"text2\"].apply(lambda x: x[:sentCutoff])\n",
    "\n",
    "validDf[\"text1\"] = validDf[\"text1\"].apply(lambda x: x[:sentCutoff])\n",
    "validDf[\"text2\"] = validDf[\"text2\"].apply(lambda x: x[:sentCutoff])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(trainDf[\"text1\"].apply(len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "def getLoader(inDf, batchSize): \n",
    "    inDf[\"text1\"] = inDf[\"text1\"].apply(lambda x: tokenizer.batch_encode_plus(x, max_length=70, padding=\"max_length\", truncation=True, return_tensors=\"pt\"))\n",
    "    inDf[\"text2\"] = inDf[\"text2\"].apply(lambda x: tokenizer.batch_encode_plus(x, max_length=70, padding=\"max_length\", truncation=True, return_tensors=\"pt\"))\n",
    "    \n",
    "    inDf[\"text1_input_ids\"] = inDf[\"text1\"].apply(lambda x: x[\"input_ids\"])\n",
    "    inDf[\"text2_input_ids\"] = inDf[\"text2\"].apply(lambda x: x[\"input_ids\"])\n",
    "    \n",
    "    inDf[\"text1_attention_mask\"] = inDf[\"text1\"].apply(lambda x: x[\"attention_mask\"])\n",
    "    inDf[\"text2_attention_mask\"] = inDf[\"text2\"].apply(lambda x: x[\"attention_mask\"])\n",
    "    \n",
    "    #inDf[\"ground_truth\"] = inDf[\"ground_truth\"].apply(lambda x: x))\n",
    "    \n",
    "    dataset = CustomSentListDataset(inDf[[\"ground_truth\", \"text1_input_ids\", \"text1_attention_mask\",\"text2_input_ids\", \"text2_attention_mask\"]])\n",
    "    \n",
    "    # convert dataset features to PyTorch tensors\n",
    "    #dataset.set_format(type='torch', columns=inDf.columns())\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True)\n",
    "    return [dataset, loader]\n",
    "\n",
    "trainData, trainLoader = getLoader(trainDf, 1)\n",
    "validData, validLoader = getLoader(validDf, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len1 = [len(item) for item in trainDf[\"text1_input_ids\"]]\n",
    "len2 = [len(item) for item in trainDf[\"text2_input_ids\"]]\n",
    "\n",
    "allLens = len1 + len2\n",
    "plt.hist(allLens, bins=100)\n",
    "plt.xlim([0, 200])\n",
    "print(np.median(allLens))\n",
    "print(np.mean(allLens))\n",
    "\n",
    "#look at the length of sentences multiplied together \n",
    "multLen = np.empty([len(len1), len(len2)])\n",
    "for i, a in enumerate(len1): \n",
    "    for j, b in enumerate(len2): \n",
    "        multLen[i, j] = a*b\n",
    "multLen = multLen.flatten()\n",
    "\n",
    "#90th quantile is 1148 \n",
    "np.quantile(multLen, .9)\n",
    "np.quantile(multLen, .8)\n",
    "#so go with 800? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(token_embeddings, attention_mask):\n",
    "     #First element of model_output contains all token embeddings\n",
    "    #print(attention_mask.unsqueeze(-1).shape)\n",
    "    #print(token_embeddings.size())\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, flatCutoff):\n",
    "        super(MyModel,self).__init__()\n",
    "        self.model = AutoModel.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "        self.cos = torch.nn.CosineSimilarity(dim=0, eps=1e-6)\n",
    "        self.flatCutoff = flatCutoff\n",
    "        self.ReLU = nn.ReLU()\n",
    "        self.l1 = nn.Linear(flatCutoff, 500).to(device)\n",
    "        self.l2 = nn.Linear(500, 500).to(device)\n",
    "        self.l3 = nn.Linear(500, 250).to(device)\n",
    "        self.l4 = nn.Linear(250, 1).to(device)\n",
    "        self.loss_func = torch.nn.MSELoss(reduction=\"mean\")\n",
    "        \n",
    "    def mean_pooling(self, token_embeddings, attention_mask): \n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "    def forward(self, inputs_ids_a, attention_a, inputs_ids_b, attention_b, gt): \n",
    "        \n",
    "        u = self.model(inputs_ids_a, attention_mask=attention_a)[0]  # all token embeddings B\n",
    "        #try to clear up memory and keep only the sentence embeddings \n",
    "        del inputs_ids_a\n",
    "\n",
    "        sents_u = mean_pooling(u, attention_a)\n",
    "        del attention_a\n",
    "        del u \n",
    "        \n",
    "        v = self.model(inputs_ids_b, attention_mask=attention_b)[0]  # all token embeddings B\n",
    "        del inputs_ids_b\n",
    "\n",
    "        sents_v = self.mean_pooling(v, attention_b)\n",
    "        del attention_b\n",
    "        del v\n",
    "        \n",
    "        #get similarity matrix for sentences between the documents \n",
    "        sims = np.empty([sents_u.shape[0], sents_v.shape[0]])\n",
    "        for i, uSent in enumerate(sents_u): \n",
    "            for j, vSent in enumerate(sents_v):\n",
    "                sims[i, j] = self.cos(uSent, vSent)\n",
    "\n",
    "        #flatten down to one dimension \n",
    "        sims = sims.flatten()\n",
    "        \n",
    "        # we know that if we get the first 800 we will have between \n",
    "        # 80% and 90% of our possible sentence combinations fully included without cutting them off \n",
    "        sims_cut = torch.Tensor(sims[:self.flatCutoff]).to(device)\n",
    "\n",
    "        #pad on the right out to len of 800\n",
    "        sims_padded = torch.nn.functional.pad(sims_cut, [0, self.flatCutoff-sims_cut.shape[0]])\n",
    "\n",
    "        del sims_cut\n",
    "\n",
    "        #first attempt is a single linear layer\n",
    "        #maybe linear combination of output is sufficient? \n",
    "        #go from 4000 > 500 > 1\n",
    "        out = self.l1(sims_padded)\n",
    "        out = self.ReLU(out)\n",
    "        out = self.l2(out)\n",
    "        out = self.ReLU(out)\n",
    "        out = self.l3(out)\n",
    "        out = self.ReLU(out)\n",
    "        pred = self.l4(out)\n",
    "        \n",
    "        \n",
    "        #print(vPredSim)\n",
    "        loss = self.loss_func(pred, gt)\n",
    "        \n",
    "        return [loss, pred, gt] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(500).to(device)\n",
    "\n",
    "trainBatch = 1\n",
    "\n",
    "# we would initialize everything first\n",
    "optim = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "\n",
    "EPOCHS=4\n",
    "\n",
    "# and setup a warmup for the first ~10% steps\n",
    "total_steps = int(len(trainData)*EPOCHS / trainBatch)\n",
    "warmup_steps = int(0.1 * total_steps)\n",
    "scheduler = get_linear_schedule_with_warmup(optim, num_warmup_steps=warmup_steps, num_training_steps=total_steps - warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(): \n",
    "    model.eval()\n",
    "    lossList = []\n",
    "    preds = []\n",
    "    gts = []\n",
    "\n",
    "    for vBatch in validLoader: \n",
    "        # prepare batches and more all to the active device\n",
    "        inputs_ids_a = vBatch[1][0].to(device)\n",
    "        attention_a = vBatch[2][0].to(device)\n",
    "        inputs_ids_b = vBatch[3][0].to(device)\n",
    "        attention_b = vBatch[4][0].to(device)\n",
    "        gt = vBatch[0].float().to(device)\n",
    "        \n",
    "        #get outputs from model \n",
    "        loss, pred, gt = model(inputs_ids_a, attention_a, inputs_ids_b, attention_b, gt)\n",
    "        \n",
    "        #get predictions and ground truth to compute training metrics with \n",
    "        lossList.append(float(loss))\n",
    "        preds.append(float(pred))\n",
    "        gts.append(float(gt))\n",
    "        \n",
    "    #print(vGT)\n",
    "    return [lossList, preds, gts]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossSmoothing = 20\n",
    "validationFreq = 200 \n",
    "\n",
    "#TODO: implement a cutoff on how many sentences of the article we can consider \n",
    "#TODO: put model in seperate class? How to make sure the params are updating \n",
    "trainDict = {}\n",
    "lossList = []\n",
    "subLossList = []\n",
    "validMetrics = []\n",
    "# increase from 1 epoch if need be \n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    model.train()  # make sure model is in training mode\n",
    "    \n",
    "    # initialize the dataloader loop with tqdm (tqdm == progress bar)\n",
    "    loop = tqdm(trainLoader, leave=True)\n",
    "    \n",
    "    #validation if at correct step \n",
    "    validMetrics.append(validation())\n",
    "    model.train()\n",
    "            \n",
    "    for i, batch in enumerate(loop): \n",
    "        # zero all gradients on each new step\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        #in practice this doesn't seem to usually actually help but worth adding? \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        #get model inputs from batch \n",
    "        inputs_ids_a = batch[1][0].to(device)\n",
    "        attention_a = batch[2][0].to(device)\n",
    "        inputs_ids_b = batch[3][0].to(device)\n",
    "        attention_b = batch[4][0].to(device)\n",
    "        gt = batch[0].float().to(device)\n",
    "\n",
    "        #get outputs from model \n",
    "        loss, pred, gt = model(inputs_ids_a, attention_a, inputs_ids_b, attention_b, gt)\n",
    "        \n",
    "        subLossList.append(loss.item())\n",
    "        if i % lossSmoothing == 0: \n",
    "            lossList.append(np.median(subLossList))\n",
    "            subLossList = []\n",
    "        \n",
    "        #update weights \n",
    "        loss.backward()\n",
    "        \n",
    "        \n",
    "        \n",
    "        optim.step()\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lossList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossIndex = [(i * lossSmoothing)/len(trainData) for i in range(len(lossList))]\n",
    "plt.plot(lossIndex, lossList)\n",
    "plt.xlabel(\"Batch Num\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.title(\"Train Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(validMetrics).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validDf = pd.DataFrame({\"loss\":[], \"pred\":[], \"true\":[], \"iter\":[]})\n",
    "validArr = np.array(validMetrics)\n",
    "\n",
    "iterNum = 0\n",
    "corrList = []\n",
    "iterList = []\n",
    "for i in range(validArr.shape[0]): \n",
    "    subDf = pd.DataFrame(validArr[i].T)\n",
    "    subDf.columns = [\"loss\", \"pred\", \"true\"]\n",
    "    subDf[\"iter\"] = [iterNum for i in range(len(subDf))]\n",
    "    iterList.append(iterNum)\n",
    "    iterNum += 1\n",
    "    validDf = pd.concat([validDf, subDf])\n",
    "    corr = np.corrcoef(subDf[\"pred\"], subDf[\"true\"])\n",
    "    corrList.append(corr[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(iterList, corrList)\n",
    "plt.xlabel(\"batch num\")\n",
    "plt.ylabel(\"pearson correlation\")\n",
    "plt.title(\"validation eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print(validArr.shape)\n",
    "\n",
    "test = validArr[1,:,:]\n",
    "#np.corrcoef(test[1], test[2])\n",
    "\n",
    "#go through each validation step\n",
    "for i in range(validArr.shape[0]): \n",
    "    subDf = pd.DataFrame(validArr[i].T)\n",
    "    subDf.columns = [\"loss\", \"pred\", \"true\"]\n",
    "    corr = np.corrcoef(subDf[\"pred\"], subDf[\"true\"])\n",
    "    print(corr)\n",
    "    \n",
    "plt.scatter(subDf[\"true\"], subDf[\"pred\"], alpha=.2)\n",
    "plt.title(\"predicted vs. ground truth \")\n",
    "plt.xlabel(\"ground truth\")\n",
    "plt.ylabel(\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validArr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validDf.loc[validDf[\"iter\"] == 1400, \"true\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check memory \n",
    "t = torch.cuda.mem_get_info()\n",
    "\n",
    "used = torch.cuda.memory_allocated(device=\"cuda:4\")\n",
    "#proportion of free memory \n",
    "#print(\"used: \" used / t[1])\n",
    "print(\"used: \" + str(t[0]/t[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
