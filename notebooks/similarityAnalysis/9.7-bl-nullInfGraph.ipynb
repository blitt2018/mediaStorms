{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set paths \n",
    "STORMS_PATH  = \"/shared/3/projects/newsDiffusion/data/processed/stormDfs/20000_90_storms.tsv\"\n",
    "ARTICLES_PATH = \"/shared/3/projects/newsDiffusion/data/processed/fullDataWith20000.tsv\"\n",
    "\n",
    "VER_2020 = \"/shared/3/projects/newsDiffusion/data/raw/NELA-gt-2020/labels.csv\"\n",
    "VER_2021 = \"/shared/3/projects/newsDiffusion/data/raw/NELA-gt-2021/labels_all.tab\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-7444354899f0>:2: DtypeWarning: Columns (4,5,12,13,15,16,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  artDf = pd.read_csv(ARTICLES_PATH, sep=\"\\t\")\n"
     ]
    }
   ],
   "source": [
    "stormsDf = pd.read_csv(STORMS_PATH, sep=\"\\t\")\n",
    "artDf = pd.read_csv(ARTICLES_PATH, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(artDf, stormsDf[['key','20000_90_average_pct','20000_90_num_over_cutoff',\\\n",
    "                          '20000_90_storm_source', '20000_90_storm']], on=\"key\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCOL = \"20000_90\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stormRows = merged.loc[merged[SCOL + \"_storm\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-df3dd340f2f9>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  stormRows[\"date\"] = pd.to_datetime(stormRows[\"date\"])\n"
     ]
    }
   ],
   "source": [
    "stormRows[\"date\"] = pd.to_datetime(stormRows[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [08:26<00:00,  5.17s/it]\n"
     ]
    }
   ],
   "source": [
    "artEdges = {}\n",
    "sourceEdges = {}\n",
    "\n",
    "WINDOW = 3\n",
    "currVal = 47806.0\n",
    "\n",
    "for currVal in tqdm(list(stormRows[SCOL].unique())): \n",
    "\n",
    "    currStorm = stormRows.loc[stormRows[SCOL] == currVal, [\"date\", \"key\", \"source\"]].set_index(\"date\")\n",
    "    minDay = min(currStorm.index)\n",
    "    maxDay = max(currStorm.index)\n",
    "\n",
    "    #get all of the starting dates for the date windows we need \n",
    "    possibleDates = pd.date_range(minDay, maxDay -  np.timedelta64(WINDOW-1, \"D\"),freq='d')\n",
    "\n",
    "    for date in possibleDates: \n",
    "\n",
    "\n",
    "        #get rows in our date time range \n",
    "        dateRows = currStorm[date : date + np.timedelta64(WINDOW-1, \"D\")]\n",
    "\n",
    "        for i in range(len(dateRows)): \n",
    "            for j in range(i+1, len(dateRows)):\n",
    "                l = dateRows.iloc[i]\n",
    "                r = dateRows.iloc[j]\n",
    "\n",
    "                #if we haven't already counted this edge \n",
    "                artTup = (l[\"key\"], r[\"key\"])\n",
    "                if artTup not in artEdges: \n",
    "\n",
    "                    #if this edge isn't in source dict add it\n",
    "                    #else, add 1 to its edge \n",
    "                    sTup = (l[\"source\"], r[\"source\"])\n",
    "                    if sTup not in sourceEdges: \n",
    "                        sourceEdges[sTup] = 1\n",
    "                    else: \n",
    "                        sourceEdges[sTup] += 1\n",
    "\n",
    "                    artEdges[artTup] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get sources, veracity scores in a dataframe\n",
    "ver2020 = pd.read_csv(VER_2020, sep=\",\")\n",
    "ver2021 = pd.read_csv(VER_2021, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we want [0, 1] -> 2, [2, 3] -> 1, [4, 5] -> 0\n",
    "ver2021[\"label\"] = pd.cut(ver2021[\"factuality\"], bins=[0, 1.1, 3.1, 5.1], labels=[2, 1, 0]).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill na in 2021 with 2020 ratings \n",
    "sourceDf = pd.merge(ver2020, ver2021[[\"source\",\"label\"]], on=\"source\", how=\"outer\")\n",
    "sourceDf[\"label\"] = sourceDf[\"label_y\"].fillna(sourceDf[\"label_x\"])\n",
    "\n",
    "#get local/national labels \n",
    "localNat = artDf[[\"source\", \"national\"]].drop_duplicates()\n",
    "sourceDf = pd.merge(sourceDf, localNat, on=\"source\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we want outlets with both local and national classification to be local \n",
    "sourceDf = sourceDf.sort_values(\"national\").drop_duplicates(subset=[\"source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceDf.loc[(sourceDf[\"source\"] == \"charlotteobserver\"), [\"national\"]] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "3.0    314\n",
       "4.0    183\n",
       "1.0    157\n",
       "2.0    121\n",
       "0.0     90\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merge everything under the \"label\" category\n",
    "#here, 4 means local \n",
    "sourceDf.loc[sourceDf[\"national\"] == False, \"label\"] = 3\n",
    "\n",
    "#only item with a -1 reliability that matters/is relevant is forbes... \n",
    "#should be rated \"reliable\"\n",
    "sourceDf.loc[sourceDf[\"source\"] == \"forbes\", \"label\"] = 0\n",
    "\n",
    "#if we have nat/local duplicates, call them local \n",
    "sourceDf = sourceDf.sort_values(\"national\").drop_duplicates(subset=[\"source\"])\n",
    "\n",
    "sourceDf[\"label\"] = sourceDf[\"label\"].fillna(4)\n",
    "\n",
    "#sanity check \n",
    "sourceDf[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stormRows = pd.merge(stormRows, sourceDf[[\"source\", \"label\"]], on=\"source\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get edges,weights from our algo above and put in dataframe \n",
    "sourceTups = list(sourceEdges.keys())\n",
    "sourceLeft = [tup[0] for tup in sourceTups]\n",
    "sourceRight = [tup[1] for tup in sourceTups]\n",
    "sourceWeights = [sourceEdges[tup] for tup in sourceTups]\n",
    "\n",
    "edgeDf = pd.DataFrame({\"first\":sourceLeft, \"second\":sourceRight, \"weight\":sourceWeights})\n",
    "edgeDf = edgeDf.sort_values(\"weight\", ascending=False)\n",
    "\n",
    "#remove self-edges\n",
    "edgeDf  = edgeDf[edgeDf[\"first\"] != edgeDf[\"second\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find edge difference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now do this for just four bubbles, one for each type of media \n",
    "#grab the top outlets in terms of publishing \n",
    "\n",
    "#get top outlets   \n",
    "CUTOFF = 200\n",
    "sourceCounts = pd.DataFrame(stormRows[[\"source\"]].value_counts()).reset_index()\n",
    "topSources = list(sourceCounts.head(CUTOFF)[\"source\"])\n",
    "\n",
    "#get all edges between top sources \n",
    "topEdgeDf = edgeDf[(edgeDf[\"first\"].isin(topSources)) & edgeDf[\"second\"].isin(topSources)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 200 outlets in storms:\n",
      "min stories published 17\n",
      "max stories published 750\n"
     ]
    }
   ],
   "source": [
    "print(f'Top {CUTOFF} outlets in storms:')\n",
    "print(f'min stories published {min(sourceCounts.head(CUTOFF)[\"count\"])}')\n",
    "print(f'max stories published {max(sourceCounts.head(CUTOFF)[\"count\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourcePairs = pd.merge(topEdgeDf, sourceDf[[\"source\",\"label\"]], left_on=\"first\", right_on=\"source\").drop(columns=[\"source\"])\n",
    "sourcePairs = pd.merge(sourcePairs, sourceDf[[\"source\", \"label\"]], left_on=\"second\", right_on=\"source\").drop(columns=[\"source\"])\n",
    "\n",
    "sourcePairs = sourcePairs.drop(columns=[\"first\", \"second\"]).groupby([\"label_x\", \"label_y\"]).agg(sum).reset_index()\n",
    "\n",
    "sourcePairs = sourcePairs.replace({0:\"reliable\", 1:\"mixed\", 2:\"unreliable\", 3:\"local\", 4:\"national no label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create graph \n",
    "G = nx.from_pandas_edgelist(sourcePairs, source=\"label_x\", target=\"label_y\", edge_attr=\"weight\", create_using=nx.DiGraph)\n",
    "\n",
    "G.remove_edges_from(nx.selfloop_edges(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "outWeights = []\n",
    "outDiffs = []\n",
    "for node in G.nodes():\n",
    "    totalOut = sum([G.edges[edge[0], edge[1]][\"weight\"] for edge in G.out_edges([node])])\n",
    "    totalIn = sum([G.edges[edge[0], edge[1]][\"weight\"] for edge in G.in_edges([node])])\n",
    "    outWeights.append(totalOut)\n",
    "    outDiffs.append(totalOut - totalIn)\n",
    "    \n",
    "nx.set_node_attributes(G, dict(zip(G.nodes(), outWeights)), name=\"outWeight\")\n",
    "nx.set_node_attributes(G, dict(zip(G.nodes(), outDiffs)), name=\"outDiffs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reliable - mixed = 81459 - 79791 = 1668\n",
      "reliable - unreliable = 13660 - 11742 = 1918\n",
      "reliable - local = 108017 - 107932 = 85\n",
      "reliable - national no label = 30664 - 27147 = 3517\n",
      "mixed - reliable = 79791 - 81459 = -1668\n",
      "mixed - unreliable = 20153 - 18205 = 1948\n",
      "mixed - local = 114669 - 116711 = -2042\n",
      "mixed - national no label = 37385 - 33932 = 3453\n",
      "unreliable - reliable = 11742 - 13660 = -1918\n",
      "unreliable - mixed = 18205 - 20153 = -1948\n",
      "unreliable - local = 16569 - 19335 = -2766\n",
      "unreliable - national no label = 6203 - 6064 = 139\n",
      "local - reliable = 107932 - 108017 = -85\n",
      "local - mixed = 116711 - 114669 = 2042\n",
      "local - unreliable = 19335 - 16569 = 2766\n",
      "local - national no label = 45881 - 40792 = 5089\n",
      "national no label - reliable = 27147 - 30664 = -3517\n",
      "national no label - mixed = 33932 - 37385 = -3453\n",
      "national no label - unreliable = 6064 - 6203 = -139\n",
      "national no label - local = 40792 - 45881 = -5089\n"
     ]
    }
   ],
   "source": [
    "#how big exactly are the differences in these links? \n",
    "#we want to try scaling the edges by their number of stories \n",
    "for edge in nx.edges(G): \n",
    "    thisEdge = G.edges[edge[0], edge[1]][\"weight\"]\n",
    "    oppEdge = G.edges[edge[1], edge[0]][\"weight\"]\n",
    "    print(f\"{edge[0]} - {edge[1]} = {thisEdge} - {oppEdge} = {thisEdge - oppEdge}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Null Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEdgeDf(sourceEdges): #get edges,weights from our algo above and put in dataframe \n",
    "    sourceTups = list(sourceEdges.keys())\n",
    "    sourceLeft = [tup[0] for tup in sourceTups]\n",
    "    sourceRight = [tup[1] for tup in sourceTups]\n",
    "    sourceWeights = [sourceEdges[tup] for tup in sourceTups]\n",
    "\n",
    "    edgeDf = pd.DataFrame({\"first\":sourceLeft, \"second\":sourceRight, \"weight\":sourceWeights})\n",
    "    edgeDf = edgeDf.sort_values(\"weight\", ascending=False)\n",
    "\n",
    "    #remove self-edges\n",
    "    edgeDf  = edgeDf[edgeDf[\"first\"] != edgeDf[\"second\"]]\n",
    "    \n",
    "    return edgeDf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get top outlets   \n",
    "CUTOFF = 200\n",
    "sourceCounts = pd.DataFrame(stormRows[[\"source\"]].value_counts()).reset_index()\n",
    "topSources = list(sourceCounts.head(CUTOFF)[\"source\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [08:22<00:00,  5.13s/it]\n",
      "100%|██████████| 98/98 [08:06<00:00,  4.96s/it]\n",
      "100%|██████████| 98/98 [07:53<00:00,  4.84s/it]\n",
      "100%|██████████| 98/98 [07:51<00:00,  4.81s/it]\n",
      "100%|██████████| 98/98 [07:56<00:00,  4.86s/it]\n",
      "100%|██████████| 98/98 [07:44<00:00,  4.74s/it]\n",
      "100%|██████████| 98/98 [08:35<00:00,  5.26s/it]\n",
      "100%|██████████| 98/98 [08:34<00:00,  5.25s/it]\n",
      "100%|██████████| 98/98 [08:28<00:00,  5.19s/it]\n",
      "100%|██████████| 98/98 [08:21<00:00,  5.12s/it]\n",
      "100%|██████████| 98/98 [08:26<00:00,  5.17s/it]\n",
      "100%|██████████| 98/98 [08:39<00:00,  5.30s/it]\n",
      "100%|██████████| 98/98 [08:30<00:00,  5.21s/it]\n",
      "100%|██████████| 98/98 [08:29<00:00,  5.20s/it]\n",
      "100%|██████████| 98/98 [08:26<00:00,  5.17s/it]\n",
      "100%|██████████| 98/98 [08:22<00:00,  5.13s/it]\n",
      "100%|██████████| 98/98 [08:22<00:00,  5.13s/it]\n",
      "100%|██████████| 98/98 [08:17<00:00,  5.07s/it]\n",
      "100%|██████████| 98/98 [08:25<00:00,  5.16s/it]\n",
      "100%|██████████| 98/98 [08:16<00:00,  5.06s/it]\n"
     ]
    }
   ],
   "source": [
    "WINDOW = 3\n",
    "N_ITERS = 20\n",
    "\n",
    "#IMPORTANT: stores null edge weights \n",
    "nullEdgeCounts = {}\n",
    "    \n",
    "for i in range(N_ITERS): \n",
    "    \n",
    "    nullArtEdges = {}\n",
    "    nullSourceEdges = {}\n",
    "\n",
    "    for currVal in tqdm(list(stormRows[SCOL].unique())): \n",
    "\n",
    "        currStorm = stormRows.loc[stormRows[SCOL] == currVal, [\"date\", \"key\", \"source\"]].set_index(\"date\")\n",
    "        minDay = min(currStorm.index)\n",
    "        maxDay = max(currStorm.index)\n",
    "\n",
    "\n",
    "        #this has the effect of shuffling the rows of the dataframe \n",
    "        shuffled = currStorm.sample(frac=1)\n",
    "\n",
    "        #now we give the shuffled dataframe the date values, so \n",
    "        #we can treat everything as normal but we have random ordering of stories \n",
    "        shuffled = shuffled.set_index(currStorm.sort_values(\"date\").index)\n",
    "\n",
    "        #get all of the starting dates for the date windows we need \n",
    "        possibleDates = pd.date_range(minDay, maxDay -  np.timedelta64(WINDOW-1, \"D\"),freq='d')\n",
    "\n",
    "        for date in possibleDates: \n",
    "\n",
    "            #get rows in our date time range \n",
    "            dateRows = shuffled[date : date + np.timedelta64(WINDOW-1, \"D\")]\n",
    "\n",
    "            for i in range(len(dateRows)): \n",
    "                for j in range(i+1, len(dateRows)):\n",
    "                    l = dateRows.iloc[i]\n",
    "                    r = dateRows.iloc[j]\n",
    "\n",
    "                    #if we haven't already counted this edge \n",
    "                    artTup = (l[\"key\"], r[\"key\"])\n",
    "                    if artTup not in nullArtEdges: \n",
    "\n",
    "                        #if this edge isn't in source dict add it\n",
    "                        #else, add 1 to its edge \n",
    "                        sTup = (l[\"source\"], r[\"source\"])\n",
    "                        if sTup not in nullSourceEdges: \n",
    "                            nullSourceEdges[sTup] = 1\n",
    "                        else: \n",
    "                            nullSourceEdges[sTup] += 1\n",
    "\n",
    "                        nullArtEdges[artTup] = True\n",
    "    \n",
    "    #beginning of code to get null distribution of edge weights\n",
    "    nullEdgeDf = getEdgeDf(nullSourceEdges)\n",
    "\n",
    "    #get all edges between top sources \n",
    "    topEdgeDf = nullEdgeDf[(nullEdgeDf[\"first\"].isin(topSources)) & nullEdgeDf[\"second\"].isin(topSources)]\n",
    "\n",
    "    #get the veracity labels \n",
    "    sourcePairs = pd.merge(topEdgeDf, sourceDf[[\"source\",\"label\"]], left_on=\"first\", right_on=\"source\").drop(columns=[\"source\"])\n",
    "    sourcePairs = pd.merge(sourcePairs, sourceDf[[\"source\", \"label\"]], left_on=\"second\", right_on=\"source\").drop(columns=[\"source\"])\n",
    "    \n",
    "    #groupy by veracity label \n",
    "    sourcePairs = sourcePairs.drop(columns=[\"first\", \"second\"]).groupby([\"label_x\", \"label_y\"]).agg(sum).reset_index()\n",
    "    sourcePairs = sourcePairs.replace({0:\"reliable\", 1:\"mixed\", 2:\"unreliable\", 3:\"local\", 4:\"national no label\"})\n",
    "    \n",
    "    #create graph \n",
    "    nullG = nx.from_pandas_edgelist(sourcePairs, source=\"label_x\", target=\"label_y\", edge_attr=\"weight\", create_using=nx.DiGraph)\n",
    "    nullG.remove_edges_from(nx.selfloop_edges(G))\n",
    "\n",
    "\n",
    "    for edge in nullG.edges():\n",
    "        weight = nullG[edge[0]][edge[1]][\"weight\"]\n",
    "        if edge not in nullEdgeCounts: \n",
    "            nullEdgeCounts[edge] = [weight]\n",
    "        else: \n",
    "            nullEdgeCounts[edge].append(weight)\n",
    "        \n",
    "    if i <= 5: \n",
    "        print(nullEdgeCounts)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reliable - mixed = 81459 - 79791 = 1668\n",
      "[2413, -2171, 2022, -441, -1686, -1628, -1724, 1195, 706, 2109, 1156, 4191, -1561, -420, -49, -717, -2746, -3836, -219, -1544]\n",
      "reliable - unreliable = 13660 - 11742 = 1918\n",
      "[1043, -168, -1427, -703, 145, 130, -74, 647, -228, 245, 103, 122, 1323, 220, 152, 50, 483, -341, 605, -292]\n",
      "reliable - local = 108017 - 107932 = 85\n",
      "[-733, 2075, 4792, -2321, -808, -805, -3393, -2691, 135, 1850, 3364, 5091, -3131, -1762, 3101, 342, 12, -3704, -1576, 769]\n",
      "reliable - national no label = 30664 - 27147 = 3517\n",
      "[1965, -674, 1310, -1002, 0, 863, -813, -460, -2057, 656, -189, 356, 33, 847, -848, -1086, 303, 573, -1305, 1026]\n",
      "mixed - reliable = 79791 - 81459 = -1668\n",
      "[-2413, 2171, -2022, 441, 1686, 1628, 1724, -1195, -706, -2109, -1156, -4191, 1561, 420, 49, 717, 2746, 3836, 219, 1544]\n",
      "mixed - unreliable = 20153 - 18205 = 1948\n",
      "[1005, 670, -2132, -1353, 657, 393, 297, 660, -337, 417, -319, -364, 1347, 674, 159, 11, 1440, -310, 782, 141]\n",
      "mixed - local = 114669 - 116711 = -2042\n",
      "[-2095, 6917, 764, 4208, -1174, 2561, -1027, -2080, -906, -1591, 2855, -473, -4, -1190, 3340, -385, 561, 2566, 1134, 2381]\n",
      "mixed - national no label = 37385 - 33932 = 3453\n",
      "[1755, 734, 775, -1225, 993, 740, 587, 63, -3313, -43, -868, -667, 1398, 1679, -732, -1000, 1948, 2616, -659, 1675]\n",
      "unreliable - reliable = 11742 - 13660 = -1918\n",
      "[-1043, 168, 1427, 703, -145, -130, 74, -647, 228, -245, -103, -122, -1323, -220, -152, -50, -483, 341, -605, 292]\n",
      "unreliable - mixed = 18205 - 20153 = -1948\n",
      "[-1005, -670, 2132, 1353, -657, -393, -297, -660, 337, -417, 319, 364, -1347, -674, -159, -11, -1440, 310, -782, -141]\n",
      "unreliable - local = 16569 - 19335 = -2766\n",
      "[-1022, 474, 2434, 1217, 47, -378, -212, -562, 276, -1310, -164, -140, -1749, -1040, 865, 221, -1277, 1292, -73, 108]\n",
      "unreliable - national no label = 6203 - 6064 = 139\n",
      "[-142, -39, 870, 206, -76, -244, -98, -375, -410, 22, -340, -117, -264, 167, 71, -227, -486, 556, -157, 305]\n",
      "local - reliable = 107932 - 108017 = -85\n",
      "[733, -2075, -4792, 2321, 808, 805, 3393, 2691, -135, -1850, -3364, -5091, 3131, 1762, -3101, -342, -12, 3704, 1576, -769]\n",
      "local - mixed = 116711 - 114669 = 2042\n",
      "[2095, -6917, -764, -4208, 1174, -2561, 1027, 2080, 906, 1591, -2855, 473, 4, 1190, -3340, 385, -561, -2566, -1134, -2381]\n",
      "local - unreliable = 19335 - 16569 = 2766\n",
      "[1022, -474, -2434, -1217, -47, 378, 212, 562, -276, 1310, 164, 140, 1749, 1040, -865, -221, 1277, -1292, 73, -108]\n",
      "local - national no label = 45881 - 40792 = 5089\n",
      "[2530, -1902, 1162, -2434, 1073, 1551, 1456, -818, -4526, 834, -2018, -1342, 399, 2106, -1955, -1888, 1806, 1568, -1413, 738]\n",
      "national no label - reliable = 27147 - 30664 = -3517\n",
      "[-1965, 674, -1310, 1002, 0, -863, 813, 460, 2057, -656, 189, -356, -33, -847, 848, 1086, -303, -573, 1305, -1026]\n",
      "national no label - mixed = 33932 - 37385 = -3453\n",
      "[-1755, -734, -775, 1225, -993, -740, -587, -63, 3313, 43, 868, 667, -1398, -1679, 732, 1000, -1948, -2616, 659, -1675]\n",
      "national no label - unreliable = 6064 - 6203 = -139\n",
      "[142, 39, -870, -206, 76, 244, 98, 375, 410, -22, 340, 117, 264, -167, -71, 227, 486, -556, 157, -305]\n",
      "national no label - local = 40792 - 45881 = -5089\n",
      "[-2530, 1902, -1162, 2434, -1073, -1551, -1456, 818, 4526, -834, 2018, 1342, -399, -2106, 1955, 1888, -1806, -1568, 1413, -738]\n"
     ]
    }
   ],
   "source": [
    "#just some helpful code for after \n",
    "#how big exactly are the differences in these links? \n",
    "#we want to try scaling the edges by their number of stories \n",
    "for edge in list(G.edges()): \n",
    "    \n",
    "    thisEdge = G.edges[edge[0], edge[1]][\"weight\"]\n",
    "    oppEdge = G.edges[edge[1], edge[0]][\"weight\"]\n",
    "    print(f\"{edge[0]} - {edge[1]} = {thisEdge} - {oppEdge} = {thisEdge - oppEdge}\")\n",
    "    \n",
    "    edgeList = nullEdgeCounts[edge]\n",
    "    oppEdgeList = nullEdgeCounts[(edge[1], edge[0])]\n",
    "     \n",
    "    print([edgeList[i] - oppEdgeList[i] for i in range(len(edgeList))])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 5., 3., 1., 1., 2., 4., 1., 0., 1.]),\n",
       " array([-2530. , -1824.4, -1118.8,  -413.2,   292.4,   998. ,  1703.6,\n",
       "         2409.2,  3114.8,  3820.4,  4526. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([edgeList[i] - oppEdgeList[i] for i in range(len(edgeList))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we'd like to look at examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#also check in on the dates for revision "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
