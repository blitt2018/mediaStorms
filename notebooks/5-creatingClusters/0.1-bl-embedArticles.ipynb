{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTake in article text for all ~5 million articles and embed them with our model \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Take in article text for all ~5 million articles and embed them with our model \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from sentence_transformers import evaluation\n",
    "import torch \n",
    "import torch.nn\n",
    "from transformers import BertModel\n",
    "from transformers import BertTokenizer\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from transformers.optimization import get_linear_schedule_with_warmup\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import sklearn.model_selection\n",
    "import sklearn\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.nn import CosineEmbeddingLoss\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can't have any na rows when calculating embeddings on content \n",
    "#NOTE: when merging back in we will need to run .dropna(columns=[\"headTail\"])\n",
    "df = pd.read_csv(\"/shared/3/projects/newsDiffusion/data/interim/NEREmbedding/headTailMerged.tsv\", sep=\"\\t\", usecols=[\"key\", \"headTail\"])\n",
    "df[\"headTail\"] = df[\"headTail\"].fillna(\"\")\n",
    "\n",
    "#/shared/3/projects/benlitterer/localNews/mergedNewsData/mergedNER.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export HF_DATASETS_CACHE=\"/shared/3/projects/newsDiffusion/data/hf_cache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = \"/shared/3/projects/newsDiffusion/data/interim/NEREmbedding/embeddingsKeys.tsv\"\n",
    "\n",
    "#the model that performed best with the 5 random seeds \n",
    "MODEL_PATH = \"/shared/3/projects/newsDiffusion/models/2.0-biModelAblation/finalModel/135/state_dict.tar\"\n",
    "DEVICE = 0\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiModel(torch.nn.Module): \n",
    "    def __init__(self):\n",
    "        super(BiModel,self).__init__()\n",
    "        self.model = AutoModel.from_pretrained('sentence-transformers/all-mpnet-base-v2').to(device).train()\n",
    "        self.cos = torch.nn.CosineSimilarity(dim=1, eps=1e-4)\n",
    "        \n",
    "    def mean_pooling(self, token_embeddings, attention_mask): \n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    \n",
    "    #NOTE: here we expect only one batch of input ids and attention masks \n",
    "    def encode(self, input_ids, attention_mask):\n",
    "        encoding = self.model(input_ids.squeeze(1), attention_mask=attention_mask.squeeze(1))[0]\n",
    "        meanPooled = self.mean_pooling(encoding, attention_mask.squeeze(1))\n",
    "        return meanPooled \n",
    "    \n",
    "    #NOTE: here we expect a list of two that we then unpack \n",
    "    def forward(self, input_ids, attention_mask): \n",
    "        \n",
    "        input_ids_a = input_ids[0].to(device)\n",
    "        input_ids_b = input_ids[1].to(device)\n",
    "        attention_a = attention_mask[0].to(device)\n",
    "        attention_b = attention_mask[1].to(device)\n",
    "        \n",
    "        #encode sentence and get mean pooled sentence representation \n",
    "        encoding1 = self.model(input_ids_a, attention_mask=attention_a)[0] #all token embeddings\n",
    "        encoding2 = self.model(input_ids_b, attention_mask=attention_b)[0]\n",
    "        \n",
    "        meanPooled1 = self.mean_pooling(encoding1, attention_a)\n",
    "        meanPooled2 = self.mean_pooling(encoding2, attention_b)\n",
    "        \n",
    "        pred = self.cos(meanPooled1, meanPooled2)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load trainedModel \n",
    "#device = torch.device(\"cuda:\" + str(DEVICE) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "trainedModel = BiModel()\n",
    "trainedModel.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "device = torch.device(\"cuda:\" + str(DEVICE))\n",
    "trainedModel = trainedModel.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e2bee4f8534546a2ebf906daebeb91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "dataset = Dataset.from_pandas(df[[\"key\", \"headTail\"]])\n",
    "dataset = dataset.map(lambda x: tokenizer(x[\"headTail\"], max_length=384, padding=\"max_length\", truncation=True, return_tensors=\"pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.remove_columns([\"headTail\"])\n",
    "dataset.set_format(type=\"torch\", columns=[\"key\", \"input_ids\", \"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a1960dbff84a10b32b191107cf60ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = []\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "outFile = open(OUTPUT_PATH, \"w\")\n",
    "for i, batch in tqdm(enumerate(loader)): \n",
    "    #print(batch)\n",
    "    ids = batch[\"input_ids\"].to(device)\n",
    "    mask = batch[\"attention_mask\"].to(device)\n",
    "    keys = batch[\"key\"].tolist()\n",
    "    \n",
    "    encodingList = trainedModel.encode(ids, mask).detach().to(\"cpu\").tolist()\n",
    "    \n",
    "    for i in range(len(keys)): \n",
    "        key = keys[i]\n",
    "        encoding = encodingList[i]\n",
    "        outFile.write(str(key) + \"\\t\" + str(encoding) + \"\\n\")\n",
    "        \n",
    "outFile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
