{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Post-hoc: we need to pickle our entity index for quick loading. This file does so \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.spatial import distance \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm \n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: very important, which entity categories to keep \n",
    "#article showing all entity types below\n",
    "# https://www.kaggle.com/code/curiousprogrammer/entity-extraction-and-classification-using-spacy\n",
    "TO_KEEP = [\"org\",\"event\", \"person\", \"work_of_art\", \"product\"]\n",
    "\n",
    "OUT_PATH = \"/shared/3/projects/newsDiffusion/data/interim/NEREmbedding/NERIndexPickled.pkl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_COLS = [\"key\", \"NamedEntities\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading news data\n"
     ]
    }
   ],
   "source": [
    "#load in main data source \n",
    "print(\"loading news data\")\n",
    "df = pd.read_csv(\"/shared/3/projects/newsDiffusion/data/processed/newsData/fullDataWithNERCleaned.tsv\",\\\n",
    "                 sep=\"\\t\", usecols=LOAD_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing\n",
      "parsed\n",
      "0 NA values in Named Entities column\n",
      "Filling with '' instead\n"
     ]
    }
   ],
   "source": [
    "#NOTE: used to have embeddings here, but don't need that anymore with current method \n",
    "print(\"parsing\")\n",
    "\n",
    "def cleanList(inList): \n",
    "    return [str(re.sub(\"[^a-zA-Z0-9 ]\", \"\", item).lower()) for item in inList]\n",
    "\n",
    "def parseList(inStr): \n",
    "    split = inStr.split(\"\\'), (\\'\")\n",
    "    return [cleanList(item.split(\"', '\")) for item in split]\n",
    "\n",
    "#parse topics from string to actual list of tuples \n",
    "df[\"NamedEntities\"] = df[\"NamedEntities\"].apply(parseList)\n",
    "\n",
    "print(\"parsed\")\n",
    "\n",
    "#test out idea for creating reverse mapping \n",
    "#how many na vals do we have in \"NamedEntities\"? \n",
    "print(str(sum(df[\"NamedEntities\"].isna())) + \" NA values in Named Entities column\")\n",
    "print(\"Filling with '' instead\")\n",
    "df[\"NamedEntities\"] = df[\"NamedEntities\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: we see below that we have things like \"date: week\" as named entities. This must be addressed somewhere "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "entDf = df.explode(\"NamedEntities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "entDf[[\"ent_type\",\"entity\"]] = pd.DataFrame(entDf[\"NamedEntities\"].tolist(), index=entDf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "entDf[[\"key\", \"ent_type\", \"entity\"]].to_pickle(OUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7436473 rows in entity-grouped df\n"
     ]
    }
   ],
   "source": [
    "#group articles by their named entities  \n",
    "entDf = entDf[[\"ent_type\", \"entity\", \"key\"]].groupby(by=[\"ent_type\", \"entity\"]).agg(list)\n",
    "\n",
    "print(str(len(entDf)) + \" rows in entity-grouped df\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
