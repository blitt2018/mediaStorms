{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlets = pd.read_csv(\"/shared/3/projects/benlitterer/localNews/NELAdata/CSVs/outlets.csv\")\n",
    "articles = pd.read_csv(\"/shared/3/projects/benlitterer/localNews/NELAdata/CSVs/articles.csv\")\n",
    "demographics = pd.read_csv(\"/shared/3/projects/benlitterer/localNews/NELAdata/CSVs/demographics.csv\")\n",
    "risks = pd.read_csv(\"/shared/3/projects/benlitterer/localNews/NELAdata/CSVs/risks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "outletDem = pd.merge(outlets, demographics, how = \"left\", on=\"fips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge data into main local news dataframe \n",
    "outletDf = pd.merge(outletDem, risks, how=\"left\", on=\"fips\")\n",
    "localDf = pd.merge(articles, outletDf, how=\"left\", on=\"sourcedomain_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "#get nela 2022\n",
    "nelaGTLocation = \"/shared/3/projects/benlitterer/localNews/NELA-gt-2020/nela-gt-2020/newsdata\"\n",
    "\n",
    "outletDfList = []\n",
    "i = 0 \n",
    "for outletName in os.listdir(nelaGTLocation): \n",
    "    if i % 50 == 0: \n",
    "        print(i)\n",
    "    i+= 1 \n",
    "    \n",
    "    #get dataframe for this outlet, add to list \n",
    "    outletPath = nelaGTLocation + \"/\" + outletName\n",
    "    outletDf = pd.read_json(outletPath)\n",
    "    outletDfList.append(outletDf)\n",
    "\n",
    "#resetting the index prevents us from getting a weird nested index later \n",
    "gtDf = pd.concat(outletDfList).reset_index(drop=True)\n",
    "gtDf = gtDf.rename({\"id\":\"gt_id\"})\n",
    "localDf = localDf.rename(columns={\"url_x\":\"url\", \"article_id\":\"local_id\"}).drop(columns=[\"url_y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['local_id', 'sourcedomain_id', 'date', 'title', 'content', 'url',\n",
       "       'fips', 'source', 'description', 'onlinesince', 'rank', 'state', 'city',\n",
       "       'lon', 'lat', 'county', 'total_population', 'white_pct', 'black_pct',\n",
       "       'hispanic_pct', 'nonwhite_pct', 'foreignborn_pct', 'female_pct',\n",
       "       'age29andunder_pct', 'age65andolder_pct', 'median_hh_inc',\n",
       "       'clf_unemploy_pct', 'lesshs_pct', 'lesscollege_pct',\n",
       "       'lesshs_whites_pct', 'lesscollege_whites_pct', 'rural_pct',\n",
       "       'ruralurban_cc', 'predrt_0', 'predrt_12', 'predrt_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "localDf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86264"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(localDf) - len(localDf.drop_duplicates([\"url\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71030"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(localDf) - len(localDf.drop_duplicates([\"url\", \"content\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56349"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(localDf) - len(localDf.drop_duplicates([\"source\", \"title\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge national and local data\n",
    "#create 'national' column \n",
    "localDf[\"national\"] = [False for i in range(0, len(localDf))]\n",
    "gtDf[\"national\"] = [True for i in range(0, len(gtDf))]\n",
    "\n",
    "#merge local and national-2020 news together \n",
    "totalDf = pd.concat([localDf, gtDf]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1445509"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(localDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1779127"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gtDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3418: DtypeWarning: Columns (1,2,6,9,10,11,12,13,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,38,39,40,41) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "#shortcut since an earlier script wrote this data here\n",
    "previousDf = pd.read_csv(\"/shared/3/projects/benlitterer/localNews/MVP1/mergedArticles.tsv\", sep=\"\\t\")\n",
    "totalDf = previousDf\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n"
     ]
    }
   ],
   "source": [
    "#get NELA-2021\n",
    "nelaGTLocation = \"/shared/3/projects/benlitterer/localNews/NELA-gt-2021/json/nela-gt-2021/newsdata\"\n",
    "\n",
    "outletDfList = []\n",
    "i = 0 \n",
    "for outletName in os.listdir(nelaGTLocation): \n",
    "    if i % 50 == 0: \n",
    "        print(i)\n",
    "    i+= 1 \n",
    "    \n",
    "    #get dataframe for this outlet, add to list \n",
    "    outletPath = nelaGTLocation + \"/\" + outletName\n",
    "    outletDf = pd.read_json(outletPath)\n",
    "    outletDfList.append(outletDf)\n",
    "\n",
    "#resetting the index prevents us from getting a weird nested index later \n",
    "gtDf = pd.concat(outletDfList).reset_index(drop=True)\n",
    "\n",
    "#create 'national' column \n",
    "gtDf[\"national\"] = [True for i in range(0, len(gtDf))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1856509"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gtDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate local, nela 2020 with nela 2021\n",
    "mergedDf = pd.concat([totalDf, gtDf]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5081145"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mergedDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(gtDf[\"url\"].isna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look into potential keys for NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288445"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data questions: \n",
    "# 1053 na titles, no na sources \n",
    "#len(mergedDf.drop_duplicates([\"title\",\"source\"]))\n",
    "\n",
    "#311152 duplicates with title + source key \n",
    "#len(mergedDf) - len(mergedDf.drop_duplicates([\"title\", \"source\"]))\n",
    "\n",
    "#194287 duplicates with title + source + content \n",
    "#so 2/3 of those are also duplicates with text\n",
    "#len(mergedDf) - len(mergedDf.drop_duplicates([\"title\", \"source\", \"content\"]))\n",
    "\n",
    "#435689 duplicate urls \n",
    "#len(mergedDf) - len(mergedDf.drop_duplicates([\"url\"]))\n",
    "\n",
    "#288445 duplicates with url + content\n",
    "#so about half of those have different content \n",
    "#len(mergedDf) - len(mergedDf.drop_duplicates([\"url\", \"content\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other data notes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we don't have any n/a sources which is good \n",
    "\n",
    "#5,081,145 is the correct number of articles to have according to the papers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['local_id', 'sourcedomain_id', 'date', 'title', 'content', 'url',\n",
       "       'fips', 'source', 'description', 'onlinesince', 'rank', 'state', 'city',\n",
       "       'lon', 'lat', 'county', 'total_population', 'white_pct', 'black_pct',\n",
       "       'hispanic_pct', 'nonwhite_pct', 'foreignborn_pct', 'female_pct',\n",
       "       'age29andunder_pct', 'age65andolder_pct', 'median_hh_inc',\n",
       "       'clf_unemploy_pct', 'lesshs_pct', 'lesscollege_pct',\n",
       "       'lesshs_whites_pct', 'lesscollege_whites_pct', 'rural_pct',\n",
       "       'ruralurban_cc', 'predrt_0', 'predrt_12', 'predrt_3', 'national', 'id',\n",
       "       'author', 'published', 'published_utc', 'collection_utc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mergedDf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure we have a completely unique index \n",
    "mergedDf = mergedDf.reset_index(drop=True)\n",
    "\n",
    "#get a new index to use as a key \n",
    "mergedDf = mergedDf.reset_index()\n",
    "mergedDf = mergedDf.rename(columns={\"index\":\"key\"})\n",
    "\n",
    "#sanity check to make sure key is unique \n",
    "len(mergedDf) - len(mergedDf.drop_duplicates([\"key\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedDf[\"content\"] = mergedDf[\"content\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write news data to output file \n",
    "mergedDf.to_csv(\"/shared/3/projects/newsDiffusion/data/processed/newsData/fullMergedNELAdata.tsv\", sep=\"\\t\", quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/shared/3/projects/newsDiffusion/data/interim/NEREmbedding/NERSplitsComplete/NERSplits0topics.tsv\", sep=\"\\t\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>1137</td>\n",
       "      <td>[('CARDINAL', 'one'), ('WORK_OF_ART', 'For Lov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>1138</td>\n",
       "      <td>[('PRODUCT', 'Frodo'), ('ORG', 'Gandalf'), ('T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>1139</td>\n",
       "      <td>[('PERSON', 'Clark'), ('DATE', 'March 23-28, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>1140</td>\n",
       "      <td>[('PERSON', 'Andy Beshear'), ('ORG', 'Healthy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>1141</td>\n",
       "      <td>[('PERSON', 'aka potluck'), ('CARDINAL', 'one'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>1142</td>\n",
       "      <td>[('ORG', 'the Louisiana State Police Special V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>1143</td>\n",
       "      <td>[('GPE', 'NATCHITOCHES'), ('PERSON', 'Missy Bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>1144</td>\n",
       "      <td>[('ORG', 'Bossier Parish School'), ('DATE', 't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>1145</td>\n",
       "      <td>[('ORG', 'LHSAA'), ('DATE', 'Friday'), ('TIME'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>1146</td>\n",
       "      <td>[('DATE', 'April 12, 2020'), ('ORG', 'The Kans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>1147</td>\n",
       "      <td>[('DATE', 'annual'), ('EVENT', 'Bossier Parish...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>1148</td>\n",
       "      <td>[('ORG', 'Ivan Community/Benton'), ('GPE', 'LA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>1149</td>\n",
       "      <td>[('GPE', 'Bossier City'), ('GPE', 'LA'), ('GPE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>1150</td>\n",
       "      <td>[('PERSON', 'John Bel Edwards'), ('DATE', 'dai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>1151</td>\n",
       "      <td>[('GPE', 'BATON ROUGE'), ('GPE', 'LA'), ('DATE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>1152</td>\n",
       "      <td>[('CARDINAL', 'millions'), ('PERSON', 'Henry O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>1153</td>\n",
       "      <td>[('MONEY', '$350 billion'), ('ORG', 'Paycheck ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>1154</td>\n",
       "      <td>[('GPE', 'Louisiana'), ('ORG', 'Fullstack Acad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>1155</td>\n",
       "      <td>[('GPE', 'Denham Springs'), ('PERSON', 'Gator ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>1156</td>\n",
       "      <td>[('ORG', 'Trump'), ('ORG', 'The Wall Street Jo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                                                  1\n",
       "1137  1137  [('CARDINAL', 'one'), ('WORK_OF_ART', 'For Lov...\n",
       "1138  1138  [('PRODUCT', 'Frodo'), ('ORG', 'Gandalf'), ('T...\n",
       "1139  1139  [('PERSON', 'Clark'), ('DATE', 'March 23-28, 2...\n",
       "1140  1140  [('PERSON', 'Andy Beshear'), ('ORG', 'Healthy ...\n",
       "1141  1141  [('PERSON', 'aka potluck'), ('CARDINAL', 'one'...\n",
       "1142  1142  [('ORG', 'the Louisiana State Police Special V...\n",
       "1143  1143  [('GPE', 'NATCHITOCHES'), ('PERSON', 'Missy Bi...\n",
       "1144  1144  [('ORG', 'Bossier Parish School'), ('DATE', 't...\n",
       "1145  1145  [('ORG', 'LHSAA'), ('DATE', 'Friday'), ('TIME'...\n",
       "1146  1146  [('DATE', 'April 12, 2020'), ('ORG', 'The Kans...\n",
       "1147  1147  [('DATE', 'annual'), ('EVENT', 'Bossier Parish...\n",
       "1148  1148  [('ORG', 'Ivan Community/Benton'), ('GPE', 'LA...\n",
       "1149  1149  [('GPE', 'Bossier City'), ('GPE', 'LA'), ('GPE...\n",
       "1150  1150  [('PERSON', 'John Bel Edwards'), ('DATE', 'dai...\n",
       "1151  1151  [('GPE', 'BATON ROUGE'), ('GPE', 'LA'), ('DATE...\n",
       "1152  1152  [('CARDINAL', 'millions'), ('PERSON', 'Henry O...\n",
       "1153  1153  [('MONEY', '$350 billion'), ('ORG', 'Paycheck ...\n",
       "1154  1154  [('GPE', 'Louisiana'), ('ORG', 'Fullstack Acad...\n",
       "1155  1155  [('GPE', 'Denham Springs'), ('PERSON', 'Gator ...\n",
       "1156  1156  [('ORG', 'Trump'), ('ORG', 'The Wall Street Jo..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
